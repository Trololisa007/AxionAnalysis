{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gwpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdates\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmdates\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgdasCode3\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m             \u001b[38;5;28;01mimport\u001b[39;00m datetime\n",
      "File \u001b[1;32m~\\Documents\\AlecAxionWork\\AxionAnalysis\\gdasCode3.py:33\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2018, GNOME Collaboration.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m## WRAPPER FUNCTIONS by Ibrahim\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgwpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimeseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeries,TimeSeriesList\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mcalendar\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gwpy'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import matplotlib.scale\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import gdasCode3\n",
    "import time,math,os,scipy\n",
    "\n",
    "from datetime             import datetime\n",
    "from datetime             import timedelta\n",
    "from scipy                import fftpack,signal,optimize,interpolate\n",
    "\n",
    "from gwpy.timeseries                  import TimeSeries,TimeSeriesList\n",
    "from pycbc                            import psd,types,filter\n",
    "from scipy.stats import chi2, chisquare,poisson,norm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import itertools\n",
    "import calendar\n",
    "import random\n",
    "import copy\n",
    "from random import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "from matplotlib import rcParams, cycler\n",
    "\n",
    "def powerFunc(x, a, b, c): \n",
    "    return (a*(x**b) + c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions:\n",
    "\n",
    "## Loading and simulating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new std load data\n",
    "def LoadData(start, \n",
    "             end,   \n",
    "             station_list, \n",
    "             timeshift = False,\n",
    "            ):\n",
    "    \n",
    "    ''' \n",
    "    LoadData gets the magnetic field and sanity data \n",
    "    (and optionallly applies a high pass filter) \n",
    "    from from all stations in the list station list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start : string\n",
    "        string representing the start time in the form '%Y-%m-%d-%H-%M'\n",
    "    end : string\n",
    "        string representing the end time in the form '%Y-%m-%d-%H-%M'\n",
    "    station_list : [string]\n",
    "        list of all stations you want to get data from \n",
    "\n",
    "\n",
    "    IMPORTANT NOTE: Load Data will return a separate MASKED ARRAY of the station names\n",
    "    with the stations that are invalid masked.\n",
    "    So by using stationArr, you can process data for each station while ignoring the stations with no data\n",
    "    without changing the number of stations in the list\n",
    "    so you can assume a certain number and order of stations in the list \n",
    "    without knowing ahead of time which ones are active\n",
    "    '''\n",
    "    nstations = len(station_list)\n",
    "    \n",
    "    dataList = TimeSeriesList()\n",
    "    sanityList = TimeSeriesList()\n",
    "\n",
    "\n",
    "    totalTime =  (datetime.strptime(end,'%Y-%m-%d-%H-%M-%S')- datetime.strptime(start,'%Y-%m-%d-%H-%M-%S')).total_seconds()\n",
    "\n",
    "    starts = [start]\n",
    "    ends = [end]\n",
    "    if timeshift:\n",
    "        starttime = datetime.strptime(start,'%Y-%m-%d-%H-%M-%S')\n",
    "        endtime = datetime.strptime(end,'%Y-%m-%d-%H-%M-%S')\n",
    "        \n",
    "        for i in range(nstations):\n",
    "            startstme = starttime + timedelta(seconds = i*ShiftTime)\n",
    "            starts.append(startstme.strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "            \n",
    "            endstme = endtime + timedelta(seconds = i*ShiftTime)\n",
    "            ends.append(datetime.strftime(endstme,'%Y-%m-%d-%H-%M-%S'))     \n",
    "    else:\n",
    "        for i in range(nstations):\n",
    "            starts.append(start) \n",
    "            ends.append(end)\n",
    "\n",
    "    mask = np.zeros(len(station_list))\n",
    "    stationArr = np.ma.masked_array(np.array(station_list), mask)    \n",
    "\n",
    "    datapath   = '/GNOMEDrive/gnome/serverdata/'\n",
    "\n",
    "    for i, station in enumerate(station_list):        \n",
    "        try:\n",
    "            if station == 'test':\n",
    "                data, sanity = GenerateNoise(totalTime, a = 1.0)\n",
    "            else:\n",
    "                # use getDataInRange() to get a TimeSeriesList of all the data between start and end\n",
    "                data1, sanity1,filelist = gdasCode3.getDataInRange(station,starts[i],ends[i], path=datapath, convert = True) \n",
    "                # join the individual TimeSeries in the list into a single TimeSeries, representing missing data with NaN\n",
    "                data = data1.join(pad=float('nan'),gap='pad')\n",
    "                sanity = sanity1.join(pad=int(0),gap='pad')\n",
    "\n",
    "#                 station-wise standard devation check    \n",
    "                if datetime.strptime(start,'%Y-%m-%d-%H-%M-%S').year == 2020:\n",
    "                    station_set = True\n",
    "                    if station   == 'berkeley02': \n",
    "                        minstdev = 2.\n",
    "                    elif station == 'berkeley01': \n",
    "                        minstdev = 4.\n",
    "                    elif station == 'daejeon01':\n",
    "                        minstdev = 0.2\n",
    "                    elif station == 'hayward01':\n",
    "                        minstdev = 0.1\n",
    "                    elif station == 'krakow01': \n",
    "                        minstdev = 0.8\n",
    "                    elif station == 'lewisburg01':  \n",
    "                        minstdev = 0.1\n",
    "                    elif station == 'mainz01': \n",
    "                        minstdev = 0.1\n",
    "                    elif station == 'losangeles01': \n",
    "                        minstdev = 1.5\n",
    "                    elif station == 'moxa01':       \n",
    "                        minstdev = 1.\n",
    "                    elif station == 'oberlin01':    \n",
    "                        minstdev = 0.2\n",
    "                    else: \n",
    "                        station_set = False\n",
    "                        print (\"Minimum standard deviation not set for \"+station+\".\")\n",
    "                    if station_set:\n",
    "                        for x in range(1,len(data)//(WindowLength*int(FSamp))+1):\n",
    "                            check_data = data[(x-1)*int(FSamp)*WindowLength:x*int(FSamp)*WindowLength]\n",
    "                            stdev = np.nanstd(check_data)\n",
    "                            if stdev < minstdev:\n",
    "                                sanity[(x-1)*WindowLength:x*WindowLength] = [0]*WindowLength\n",
    "                                #print (\"unreasonably low standard deviation found: \",round(stdev,4),\" pT\")\n",
    "                else:\n",
    "                    print (\"Minimum standard deviation not set for \" + str(starttime.year) + \".\")\n",
    "\n",
    "            #check to make sure there are enough sane data for analysis\n",
    "            #Note that requirements are most strict if filtering\n",
    "            \n",
    "            assert sanity.value[np.nonzero(sanity.value)].size>0, \"no sane data for station {}\".format(station)\n",
    "        \n",
    "            count = 0\n",
    "            passing = False\n",
    "            s=0\n",
    "\n",
    "            minPassingRun = 60 # at least 1 minute of continuously sane data\n",
    "           \n",
    "            while (not passing) and (s < sanity.value.size):\n",
    "                if sanity[s] >= 1:\n",
    "                    count += 1\n",
    "                    s+=1\n",
    "                    if count >= minPassingRun: \n",
    "                        passing = True\n",
    "                else:\n",
    "                    count = 0\n",
    "                    s+=1\n",
    "            \n",
    "            #print(station)\n",
    "            assert passing, \"not enough sane data for analysis (< {} consecutive seconds)\".format(minPassingRun)\n",
    "            \n",
    "            # flag each ±1 s of time series data with the appropriate sanity value\n",
    "            data_arr = np.copy(data.value)\n",
    "            sanity_arr = sanity.value\n",
    "            isSane = np.ones(data_arr.shape)\n",
    "            isSane[0:int(FSamp)] *= sanity_arr[0]\n",
    "            for pt, val in enumerate(sanity_arr[1:-1]):\n",
    "                if val < 0.5: isSane[(pt)*int(FSamp): (pt+2)*int(FSamp)] *= int(val)\n",
    "            isSane[-int(FSamp):] *= sanity_arr[-1]\n",
    "            isSane = (isSane-1)*-1\n",
    "            \n",
    "            #double check that missing data are flagged as insane\n",
    "            isSane[np.isnan(data_arr)] = 1\n",
    "                \n",
    "            bad = np.nonzero(isSane)[0]\n",
    "\n",
    "            data_arr[np.nonzero(isSane)] = np.nan\n",
    "            tme = data_arr.size/FSamp\n",
    "\n",
    "            if data_arr.size < totalTime*FSamp: \n",
    "                print(\"data size mismatch for station {}, padding end\".format(station))\n",
    "                data_arr = np.pad(data_arr, pad_width = (0, int(totalTime*FSamp) - data_arr.size), mode = 'constant', constant_values = (np.nan,))\n",
    "                sanity_arr = np.pad(sanity_arr, pad_width = (0, int(totalTime) - sanity.size), mode = 'constant', constant_values = (np.nan,))\n",
    "                sanity = TimeSeries(sanity_arr, sample_rate = sanity.sample_rate)\n",
    "\n",
    "            dtimes = np.arange(0, tme, 1./FSamp)\n",
    "            stimes = np.arange(0,tme)\n",
    "            data_ts= TimeSeries(data_arr, times = dtimes, sample_rate = data.sample_rate)\n",
    "            \n",
    "            dataList.append(data_ts)\n",
    "            sanityList.append(sanity)\n",
    "            \n",
    "        except AssertionError as error:\n",
    "            stationArr[i] = np.ma.masked\n",
    "            print(error)\n",
    "        except:\n",
    "            raise\n",
    "    #station_list[:] = stationArr[~stationArr.mask]\n",
    "\n",
    "    return dataList, sanityList, stationArr, starts, ends\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Time Shuffled Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n",
    "\n",
    "def LoadTimeShuffled(ndatesA,\n",
    "                    fullStationListA,\n",
    "                    fullUncA,\n",
    "                    fullSpinCorrA,\n",
    "                    fullBandCorrA,\n",
    "                    nstationsavgA,\n",
    "                    realDataA = True,\n",
    "                    timeShiftA = False\n",
    "                    ):\n",
    "\n",
    "    # randomize list of station names to make full_station_list\n",
    "    #    full_station_list_2 = random.sample(full_station_list, len(full_station_list))\n",
    "\n",
    "    templist = list(zip(fullStationListA, fullUncA, fullSpinCorrA, fullBandCorrA)) #Zips station name with uncertainties and corrections \n",
    "    random.shuffle(templist) #Suffles list\n",
    "    fullStationList2, fullUnc2 , fullSpinCorr2, fullBandCorr2 = zip(*templist) #Unzips shuffled list\n",
    "      \n",
    "    \n",
    "\n",
    "    if RealData:\n",
    "        stationList  = list(fullStationList2)\n",
    "    else:\n",
    "        stationList = []\n",
    "        for i in range(0, numberOfStations): stationList.append('test')        \n",
    "  \n",
    "    \n",
    "    fullUncR      = np.asarray(fullUnc2)\n",
    "    fullSpinCorrR = np.asarray(fullSpinCorr2)\n",
    "    fullBandCorrR = np.asarray(fullBandCorr2)\n",
    "    \n",
    "\n",
    "    datalistR   = np.empty(ndatesA, dtype = list) #Initialize data list\n",
    "    sanitylistR = np.empty(ndatesA, dtype = list) #Initialize sanity list\n",
    "    startTimes  = np.empty(ndatesA, dtype = list)\n",
    "    endTimes    = np.empty(ndatesA, dtype = list)\n",
    "    \n",
    "\n",
    "\n",
    "    stationsR = np.empty(ndatesA, dtype = np.ma.masked_array)\n",
    "\n",
    "    for j in range(ndatesA):\n",
    "\n",
    "        datalistR[j], sanitylistR[j], stationsR[j], startTimes[j], endTimes[j] = LoadData(windowStarts[j], \n",
    "                                                                                  windowEnds[j],\n",
    "                                                                                  stationList, \n",
    "                                                                                  timeshift = timeShiftA\n",
    "                                                                                  )\n",
    "\n",
    "        if realDataA:\n",
    "            nstationsavgA += np.ma.count(stationsR[j])\n",
    "            nstationsavgR = nstationsavgA \n",
    "        else:\n",
    "            nstationsavgR = numberOfStations\n",
    "            stationListTemp   = intersection(fullStationList2, fullStationListA[0:numberOfStations])\n",
    "\n",
    "\n",
    "            temp = np.ma.masked_array(np.array(fullStationList2), np.zeros(len(fullStationList2))) \n",
    "            for t,station in enumerate(fullStationList2):\n",
    "                if station not in stationListTemp:\n",
    "                    temp[t] = np.ma.masked          \n",
    "\n",
    "            stationsR[j] = temp            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    if realDataA:\n",
    "        nstationsavgR = np.int64(nstationsavgR/ndatesA)   \n",
    "            \n",
    "    \n",
    "    return datalistR, sanitylistR, fullUncR, fullSpinCorrR , fullBandCorrR, stationsR, nstationsavgR, startTimes, endTimes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Generate Gaussian Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Functions to generate Gaussian Noise time series, one with just noise and the other with a signal burst\n",
    "\n",
    "def GenerateNoise(l, a = 1.): #l = total time in seconds\n",
    "    x=np.arange(0.,float(l),1./FSamp)\n",
    "    y= a*np.random.normal(loc=0,size=x.size)\n",
    "\n",
    "    GenNoise = TimeSeries(y, sample_rate = FSamp)\n",
    "    SanityNoise = TimeSeries(np.ones(int(l)), sample_rate = 1.)\n",
    "    \n",
    "    return GenNoise, SanityNoise\n",
    "\n",
    "\n",
    "def GenerateDataBurst(data_ts, a, k, dur, burstStart):\n",
    "    '''\n",
    "    Injects a sinusoidal burst into an existing time series.   \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_ts : TimeSeries\n",
    "        time series in which you want to inject the signal\n",
    "    a : float\n",
    "        burst ampl [pT] \n",
    "    k : float\n",
    "        burst frequency [Hz]\n",
    "    dur : int\n",
    "        burst duration [s]\n",
    "    burstStart : int\n",
    "        start time for the burst [s]\n",
    "    '''\n",
    "\n",
    "    s = data_ts.size/FSamp\n",
    "    x = np.arange(0.,s,1./FSamp)\n",
    "    burst = a*np.sin(2.*np.pi*k*x)\n",
    "    data_arrA = np.copy(data_ts.value)\n",
    "    assert(burstStart<=s), \"invalid start time value for injected burst (only {} seconds of data)\".format(s)\n",
    "    endt = burstStart+dur\n",
    "    if endt > s:\n",
    "        endt = s\n",
    "    data_arrA[int(np.round(burstStart*FSamp)):int(np.round(endt*FSamp))] = data_arrA[int(np.round(burstStart*FSamp)):int(np.round(endt*FSamp))]+burst[0:int(np.round(dur*FSamp))] \n",
    "    \n",
    "    dataBurst = TimeSeries(data_arrA, sample_rate = FSamp)\n",
    "    return dataBurst\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def insertEvent(station_listA, ts_listA, durationA, freqA, RA, thetaA, phiA, starttA = 500, degreesA = True):\n",
    "    newListR = TimeSeriesList()\n",
    "    \n",
    "    if degreesA:\n",
    "        thetaA = thetaA*(np.pi/180.)\n",
    "        phiA = phiA*(np.pi/180.)\n",
    "        \n",
    "        \n",
    "        xdir = RA*np.sin(phiA)*np.cos(thetaA)\n",
    "        ydir = RA*np.sin(phiA)*np.sin(thetaA)\n",
    "        zdir = RA*np.cos(phiA)\n",
    "        \n",
    "    else:\n",
    "        xTemp = random.uniform(-1, 1)\n",
    "        yTemp = random.uniform(-1, 1)\n",
    "        zTemp = random.uniform(-1, 1) \n",
    "        tempNorm = np.sqrt((xTemp)**2 + (yTemp)**2 + (zTemp)**2)\n",
    "        xdir = RA*(xTemp/tempNorm)\n",
    "        ydir = RA*(yTemp/tempNorm)\n",
    "        zdir = RA*(zTemp/tempNorm)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "#     print (\"!!!!@@@\",RA,(xdir**2 + ydir**2 + zdir**2) )\n",
    "\n",
    "\n",
    "\n",
    "    bx, by, bz = initializeVectorSpace(station_listA)\n",
    "    amplitudesR = xdir*bx + ydir*by + zdir*bz\n",
    "    propVectR = np.array([xdir,ydir,zdir])\n",
    "    #print(\"\\nPropagation vector: {} \\ninjected amplitudes: \\n{}\".format(np.round([xdir,ydir,zdir], 4), np.round(amplitudes, 6)))\n",
    "\n",
    "    for ts, ampA in zip(ts_listA, amplitudesR):\n",
    "        newListR.append(GenerateDataBurst(ts, a = ampA, k = freqA, dur = durationA, burstStart =starttA))\n",
    "\n",
    "    return newListR, amplitudesR,propVectR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_initial_spec(ep_stationA,txA,fxA,SxxA,logplotA, normalized = False):\n",
    "    \n",
    "    f0, ax = plt.subplots(1,figsize=(9,5))\n",
    "    if logplotA == True:\n",
    "        im = ax.pcolormesh(txA,fxA,SxxA,norm = matplotlib.colors.LogNorm())\n",
    "    else:\n",
    "        im = ax.pcolormesh(txA,fxA,SxxA)\n",
    "    ax.set_xlabel('time (s)')\n",
    "    ax.set_ylabel('freq (Hz)')\n",
    "    ax.set_yscale('symlog', nonposy = 'clip')\n",
    "    if normalized:\n",
    "        ax.set_title(str(ep_stationA)+' Whitened Spectrogram Before Summing Tiles')\n",
    "    else:\n",
    "        ax.set_title(str(ep_stationA)+' Unwhitened Spectrogram Before Summing Tiles')\n",
    "    \n",
    "    ax.grid(False)\n",
    "    f0.colorbar(im, ax=ax)\n",
    "    plt.show()\n",
    "    \n",
    "def show_avg_psd(ep_stationA,fxA,SkA):\n",
    "        \n",
    "    plt.title(str(ep_stationA)+\" Average PSD\")\n",
    "    plt.ylabel(\"average PSD\")\n",
    "    plt.xlabel(\"frequency\")\n",
    "    plt.plot(fxA,SkA)\n",
    "    plt.yscale('log',nonposy = 'clip')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plotEventMap(eventSpec0A, TLimitA, tTileWidthA, stageA):\n",
    "    \n",
    "    ts = np.arange(0., TLimitA, tTileWidthA)\n",
    "    figure, ax1 = plt.subplots(1, figsize = (8,4))\n",
    "    im = ax1.pcolormesh(ts, fs, eventSpec0A)\n",
    "    ax1.set_xlabel('time (s)')\n",
    "    ax1.set_ylabel('freq (Hz)')\n",
    "    ax1.set_yscale('symlog',nonposy = 'clip')  \n",
    "    ax1.set_title('stage '+ stageA + ' flagged events')\n",
    "    ax1.colorbar(im)\n",
    "    plt.show()\n",
    "                \n",
    "def plotSummedSpec(stationA, tSDataA, tF0A, tLimitA, nTTilesA, deltaTA, bwlimA, nChanA , deltaFA, logplotA):\n",
    "    \n",
    "    tx1 = np.linspace(0, tLimitA, nTTilesA + 1)\n",
    "    fx1 = np.linspace(deltaFA, bwlimA, nChanA)    \n",
    "    f, (a0, a1) = plt.subplots(2,1, gridspec_kw = {'height_ratios':[4,1]},figsize=(9,6),sharex=True)\n",
    "    tme = np.linspace(0,tLimitA,np.size(tSDataA))\n",
    "    a1.plot(tme,tSDataA)\n",
    "    if logplotA == True:\n",
    "        im1 = a0.pcolormesh(tx1,fx1,2.*tF0A, norm = matplotlib.colors.LogNorm())\n",
    "    else:\n",
    "        im1 = a0.pcolormesh(tx1,fx1,2.*tF0A)\n",
    "    a1.set_xlabel('time (s)')\n",
    "    a1.set_ylabel('amplitude (pT)')\n",
    "    a0.set_ylabel('freq (Hz)')\n",
    "    a0.set_yscale('symlog',nonposy = 'clip')\n",
    "    a0.grid(False)\n",
    "    a0.set_title(str(stationA)+' Excess Power: Delta T = '+ str(deltaTA)+' s. Delta f = '+ str(deltaFA)+' Hz. ')\n",
    "    axs = [a0,a1]\n",
    "    f.colorbar(im1,ax=axs)\n",
    "    plt.show()\n",
    "    \n",
    "def plotTimeSeries(stationA, tSDataA, tLimitA, startTimeA, endTimeA):\n",
    "    \n",
    "    tme = np.linspace(0, tLimitA, np.size(tSDataA))\n",
    "    figure, ax = plt.subplots(1, figsize = (8,4))\n",
    "    ax.plot(tme,tSDataA)\n",
    "    ax.set_xlabel('time (s)')\n",
    "    ax.set_ylabel('amplitude (pT)')\n",
    "    plt.show()\n",
    "    \n",
    "def plotAllTimeSeries(stationsA, datalistsA, tLimitA, startTimesA, endTimesA):\n",
    "    \n",
    "    numStations = np.size(stationsA)\n",
    "    timeStart = []\n",
    "    timeStart = [i*ShiftTime for i in range(numStations)]\n",
    "    timeEnd = []\n",
    "    timeEnd = [i*ShiftTime + tLimitA for i in range(numStations)]\n",
    "    \n",
    "    vertOffset = []\n",
    "    vertOffset = [i*100 for i in range(numStations)]\n",
    "    #vertOffset = [0,25,50,75,125,250]\n",
    "    \n",
    "    figure, ax = plt.subplots(1, figsize = (8,4))\n",
    "    \n",
    "    for i in range(np.size(active)):\n",
    "        tme = np.linspace(timeStart[i], timeEnd[i], np.size(datalistsA[0]))\n",
    "        ax.plot(tme, datalistsA[i]-np.mean(datalistsA[i])-vertOffset[i], label = stationsA[i])\n",
    "        ax.legend()\n",
    "    \n",
    "    ax.set_xlabel('time (s)')\n",
    "    ax.set_ylabel('amplitude (pT)')\n",
    "    plt.show()\n",
    "\n",
    "def plotAllPSDs(stationsA, fxA, Sk_normedA):\n",
    "    \n",
    "    numStations = np.size(stationsA)\n",
    "    \n",
    "    for i in range(numStations):\n",
    "        plt.plot(fxA, Sk_normedA, label = stationsA[i])\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.title(str(ep_stationA)+\" Average PSD\")\n",
    "    plt.ylabel(\"average PSD\")\n",
    "    plt.xlabel(\"frequency\")\n",
    "    plt.yscale('log',nonposy = 'clip')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotAllTimeSeries(active, datalist[0], TLimit, startTimes[0], endTimes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get chisquared value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetChisqr(ep_array, \n",
    "              dt, \n",
    "              df, \n",
    "              binw = 60, \n",
    "              log = False,\n",
    "              showplot = True,\n",
    "    ):\n",
    "    \n",
    "    dof = 2.0*dt*df\n",
    "    Mvals=np.reshape(ep_array,-1);    \n",
    "    hist, x = np.histogram(Mvals, bins = binw, density = False) \n",
    "    nbins = x.size-1\n",
    "    binwidth = x[1]-x[0]    \n",
    "    binscenter = x[1:]-binwidth/2\n",
    "    y = chi2.pdf(binscenter, dof, loc = 0)\n",
    "    sigma_hist = np.sqrt(hist)\n",
    "    \n",
    "   \n",
    "    normalize = np.sum(hist*binwidth)\n",
    "    hist_normed = hist/normalize\n",
    "    sigma_normed = sigma_hist/normalize\n",
    "    hist_norm_nz = hist_normed[np.nonzero(hist_normed)]\n",
    "    sigma_norm_nz = sigma_normed[np.nonzero(hist_normed)]\n",
    "    y_nz = y[np.nonzero(hist_normed)]\n",
    "    x_nz = binscenter[np.nonzero(hist_normed)]\n",
    "    \n",
    "    chisqrd = np.sum(((hist_norm_nz-y_nz)/sigma_norm_nz)**2.0)\n",
    "    reduced_chisqrd = chisqrd/(hist_norm_nz.size)\n",
    "        \n",
    "    if showplot:        \n",
    "        f, (ax0,ax1) = plt.subplots(2, figsize= (10,8))\n",
    "        ax0.hist(Mvals, bins = nbins, density = True)\n",
    "        ax0.errorbar(binscenter, hist_normed, yerr = sigma_normed, fmt = '.')\n",
    "        ax1.hist(Mvals, bins = nbins, density = True)\n",
    "        ax1.errorbar(binscenter, hist_normed, yerr = sigma_normed, fmt = '.')\n",
    "        ax1.semilogy(binscenter,y,'r-', label ='Chi-Square dist (dof = {}) \\n $\\delta t$: {} s \\n $\\delta f$: {} Hz'.format(dof, dt, df))\n",
    "        ax0.plot(binscenter,y,'r-', label =\"Chi-Square dist (dof = {}) \\n $\\delta t$: {} s \\n $\\delta f$: {} Hz \\n reduced $\\chi^2$: {}\".format(dof, dt, df,reduced_chisqrd))\n",
    "        ax0.set_xlabel('$\\chi^2$')\n",
    "        ax0.set_ylabel('Probability density')  \n",
    "        ax0.legend()\n",
    "        ax1.set_xlabel('$\\chi^2$')\n",
    "        ax1.set_ylabel('Probability density')  \n",
    "        ax1.legend()\n",
    "        plt.show()\n",
    "    return reduced_chisqrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EPcutoff(EPspect, thold):\n",
    "    \"\"\" Given a matrix EP and a threshold thold, this function returns all the element greater than the threshold.\"\"\"   \n",
    "    EPspect2 = np.zeros(EPspect.shape)\n",
    "    EPspect2[EPspect > thold] = 1\n",
    "    return EPspect2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that is solved by finding its roots to determine the values of x that give a prob. of chi^2 > beta\n",
    "def betart(x, dof, beta):\n",
    "    return scipy.integrate.quad(chi2.pdf, x, np.inf, args = dof)[0] - beta\n",
    "\n",
    "#Function accounts for the possible combinations given the number of stations number of coincidences required\n",
    "def betacomb(p,Nst,nCoinA,beta):\n",
    "    q = -beta\n",
    "    for i in range(nCoinA, Nst):\n",
    "        q += scipy.special.binom(Nst, i)*(p**i)*((1-p)**(Nst-i))\n",
    "    return q \n",
    "\n",
    "def calcmulti(Nst, nCoinA = 3, beta = 2.7*10.**-7):\n",
    "    sol = scipy.optimize.fsolve(betacomb, beta, args = (Nst, nCoinA, beta))\n",
    "    return sol\n",
    "\n",
    "#Calculates the excess power above which the tail has a fractional probability of betaA assuming Gaussian noise. \n",
    "#The sigma is just used to estimate the starting guess for fsolve.\n",
    "def calculatecutoff(dofA, NstA, nCoinA = 4, betaA = 2.7*10.**-7, sigmaA = 5. ):\n",
    "    beta2 = calcmulti(NstA, nCoinA, betaA)\n",
    "    sol = scipy.optimize.fsolve(betart, dofA+sigmaA*np.sqrt(2.*dofA), args = (dofA, beta2))\n",
    "    return sol\n",
    "\n",
    "\n",
    "#Returns the probability for finding an excess power larger than ep_star for a given dof, number pf stations and number of coincidences \n",
    "def Q0(ep_star, dof, Nst, nCoinA): \n",
    "    q = 0\n",
    "    p = scipy.integrate.quad(chi2.pdf, ep_star, np.inf, args = dof)[0]\n",
    "    for i in range(nCoinA, Nst+1):\n",
    "        q += scipy.special.binom(Nst, i)*(p**i)*((1-p)**(Nst-i))\n",
    "    return q\n",
    "\n",
    "def generateThresholds(tsumsA, chanPerTileA, nstationsavgA, nCoinA=4, betaA=0.003, sigmaA = 3.):\n",
    "    \n",
    "    #Calculates the EP value so that the area of the tail of the associated prob. dist. has a probabilty of beta for each number of tiles summed\n",
    "    #Takes into account the coincidence of the stations\n",
    "    \n",
    "    # Set initialize the EP thresholds array that will be used\n",
    "    thresholdsR = np.zeros((ntsums, nThreshs))\n",
    "\n",
    "    for i,n in enumerate(np.arange(imint,imaxt+1,1)):\n",
    "        thresholdmax = thresholdmaxs[n]\n",
    "        thresholdmin = thresholdmins[n]\n",
    "        #Creates a list of excess power thresholds at which the false prob will be calcuated; nt=number of thresholds\n",
    "        thresholdsR[i,:] = np.linspace(thresholdmin, thresholdmax, nThreshs) \n",
    "    return thresholdsR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency check functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeVectorSpace(stationlist, gs = False,testing = False):\n",
    "\n",
    "    # The gs arguement squares the amplitude projections. This might be because we are detecting power, \n",
    "    # but it is being called with gs=False, currently.\n",
    "    \n",
    "    numstations = len(stationlist)\n",
    "    # (Latitude, Longitude, Azimuth(0 north, 90 east, 180 south, 270 west), Altitude(0 horizon, 90 zenith))\n",
    "    \n",
    "    stationDict  = {\n",
    "        'beijing01': (40.2, 116., 251., 0.), \n",
    "        'berkeley01': (37.9, -122., 28., 0.),\n",
    "        'berkeley02':(37.9, -122., 0., 90.),\n",
    "        'canberra01': (-35.3, 149, 0., 0.),\n",
    "        'daejeon01': (36.2, 127., 0., 90.),\n",
    "        'fribourg01': (46.8, 7.16, 190., 0.),\n",
    "        'hayward01': (37.7, -122., 0., -90.),   \n",
    "        'hefei01': (31.8, 117., 90., 0.),\n",
    "        'krakow01':(50.0, 19.9, 45., 0.),\n",
    "        'lewisburg01': (41.0, -76.9, 0., 90.),    \n",
    "        'losangeles01':(34.1, -118., 270., 0.),\n",
    "        'mainz01': (50.0, 8.25, 0., -90.),    \n",
    "        'oberlin01': (41.2, -82.1, 300., 0.),\n",
    "        'stuttgart01':(48.7, 9.10, 0., 0.),\n",
    "        'moxa01':(50.6, 11.6, 270., 0.)\n",
    "        }\n",
    "     \n",
    "    latitude = np.zeros(numstations)\n",
    "    longitude =  np.zeros(numstations)\n",
    "    azimuth =  np.zeros(numstations)\n",
    "    altitude =  np.zeros(numstations)\n",
    "    directionmat = np.zeros((numstations, 3))\n",
    "    for i,station in enumerate(stationlist):\n",
    "        location = stationDict.get(station)\n",
    "        latitude[i] = (location[0])\n",
    "        longitude[i] = (location[1])\n",
    "        azimuth[i] = location[2]\n",
    "        altitude[i] = location[3]\n",
    "        \n",
    "        #Create a direction matrix consisiting of the (x,y,z) direction of sensitive axis in Earth-centered frame\n",
    "        directionmat[i] = xyzCoordinates(latitude[i], longitude[i], azimuth[i], altitude[i])\n",
    "    \n",
    "    directionmat[np.abs(directionmat) < (10.**(-10))] = 0.0\n",
    "    xSignal = directionmat[:,0]\n",
    "    ySignal = directionmat[:,1]\n",
    "    zSignal = directionmat[:,2]\n",
    "    \n",
    "    if gs:\n",
    "        xSignal = directionmat[:,0]**2\n",
    "        ySignal = directionmat[:,1]**2\n",
    "        zSignal = directionmat[:,2]**2\n",
    "        xnorm = np.linalg.norm(xSignal)\n",
    "        ynorm = np.linalg.norm(ySignal)\n",
    "        znorm = np.linalg.norm(zSignal)    \n",
    "        if xnorm > 0.: xSignal = xSignal/np.linalg.norm(xSignal)\n",
    "        if ynorm > 0.: ySignal = ySignal/np.linalg.norm(ySignal)\n",
    "        if znorm > 0.: zSignal = zSignal/np.linalg.norm(zSignal)\n",
    "\n",
    "        ySignal = ySignal - (np.dot(xSignal, ySignal)*xSignal)\n",
    "        ynorm = np.linalg.norm(ySignal)\n",
    "        if ynorm > 0.: ySignal = ySignal/ynorm\n",
    "\n",
    "        zSignal = zSignal - np.dot(ySignal, zSignal)*ySignal - np.dot(xSignal, zSignal)*xSignal\n",
    "        znorm = np.linalg.norm(zSignal)\n",
    "        if znorm > 0.: zSignal = zSignal/znorm  \n",
    "        \n",
    "    return xSignal, ySignal, zSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returns the direction of the sensitive axis in a (x,y,z) coordinates for Earth centered frame.\n",
    "# x axis goes through Longitude = 0\n",
    "# y axis goes through longitude = 90\n",
    "# z axis goes through latitude = 90 (i.e the north pole)\n",
    "\n",
    "#Check the azimuth\n",
    "\n",
    "def xyzCoordinates(lat, lon, az, alt):\n",
    "    # station location in spherical coordinates \n",
    "    # (math convention theta from x, phi from z)\n",
    "    Ltheta = (lon)*np.pi/180.\n",
    "    Lphi = (90. - lat)*np.pi/180.\n",
    "    Lr = 1.0\n",
    "\n",
    "    # station location in cartesian coordinates (wrt the center of the earth)\n",
    "    Lx = Lr*np.sin(Lphi)*np.cos(Ltheta)\n",
    "    Ly = Lr*np.sin(Lphi)*np.sin(Ltheta)\n",
    "    Lz = Lr*np.cos(Lphi)\n",
    "    L = np.array([Lx, Ly, Lz])\n",
    "\n",
    "    # calculate North direction vector:\n",
    "    Nx = -Lx\n",
    "    Ny = -Ly\n",
    "    Nz = (Lx**2.+Ly**2.)/Lz\n",
    "    \n",
    "    # normalizing \n",
    "    Nmag = np.sqrt(Nx**2.+Ny**2.+Nz**2.) \n",
    "    Nx = Nx/Nmag\n",
    "    Ny = Ny/Nmag\n",
    "    Nz = Nz/Nmag\n",
    "    N = np.array([Nx, Ny, Nz])\n",
    "\n",
    "    # calculate West direction vector ((N,W,L) analogous to (x, y, z)):\n",
    "    W = np.cross(L,N, axisa = 0, axisb = 0, axisc = 0)\n",
    "    Wx = W[0]\n",
    "    Wy = W[1]\n",
    "    Wz = W[2]\n",
    "    \n",
    "    # L dot v = Lv cos phi = cos phi\n",
    "    # N dot v = Nv cos theta = cos theta\n",
    "    \n",
    "    # sensitive axis in (r', theta', phi') coordinates (centered on station)\n",
    "    phip = (90.-alt)*np.pi/180.    \n",
    "    thetap = -az*np.pi/180.   \n",
    "    rp = 1.0\n",
    "\n",
    "    vN = rp*np.sin(phip)*np.cos(thetap)\n",
    "    vW = rp*np.sin(phip)*np.sin(thetap)\n",
    "    vL = rp*np.cos(phip)  \n",
    "    vp = [vN, vW, vL]\n",
    "    \n",
    "    R = np.array([[Nx, Wx, Lx], [Ny, Wy, Ly], [Nz, Wz, Lz]])\n",
    "\n",
    "    direction = np.matmul(R, vp) \n",
    "    direction[np.abs(direction) < (10.**(-10))] = 0.0\n",
    "    \n",
    "    directionnorm = np.linalg.norm(direction)\n",
    "    if directionnorm > 0: direction = direction/directionnorm\n",
    "\n",
    "    return direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes spectrogram and sums time tiles, there is no frequency summing\n",
    "#Returns both normalized and unnormalized spectrograms with the time tiles summed\n",
    "\n",
    "def EP0(ts_data,\n",
    "        segments_per_tile = 1,\n",
    "        channels_per_tile = 1,\n",
    "        deltaTMinA = 1.0,\n",
    "        ep_station = 'test',\n",
    "        bwlim = 100.0,\n",
    "        window = 'boxcar', \n",
    "        makeplot = False,\n",
    "        show_intermediate = False,\n",
    "        logplot = True\n",
    "        ):\n",
    "      \n",
    "    deltaTMinA = float(deltaTMinA)   \n",
    "    tLim = np.size(ts_data)/FSamp #Defines the time length of the data set\n",
    "    n_samp_per_seg = int(deltaTMinA * FSamp)    # number of samples in one time segment\n",
    "    \n",
    "    ####################################################################################\n",
    "    #Below is the code for generating overlapping windows. Only the boxcar is being used\n",
    "    dtoverlap = 0\n",
    "    deltaToverlap = 0.0\n",
    "\n",
    "    if window == 'hann': \n",
    "        deltaToverlap = deltaTMinA/2\n",
    "        dtoverlap = int(n/2)\n",
    "        \n",
    "    elif window == 'boxcar':\n",
    "        dtoverlap = 0\n",
    "        deltaToverlap = 0.0\n",
    "    \n",
    "    elif window == 'tukey': \n",
    "        window = ('tukey',0.25)   \n",
    "        dtoverlap = int(n_samp_per_seg/8)\n",
    "        deltaToverlap = dtoverlap/FSamp\n",
    "    \n",
    "    else: \n",
    "        print(\"window changed to boxcar window\")\n",
    "        window = 'boxcar'   \n",
    "\n",
    "    ###################################################################################    \n",
    "    data_arr = np.array(ts_data.value) #make array of the time series\n",
    "    \n",
    "    #time:\n",
    "    total_size = data_arr.size   \n",
    "    nsegments = int((total_size - dtoverlap) / (n_samp_per_seg - dtoverlap)) \n",
    "    nTtiles = int(nsegments/segments_per_tile)\n",
    "    deltaT = segments_per_tile*deltaTMinA\n",
    "    segments_per_tile = int(segments_per_tile)\n",
    "    \n",
    "    #frequency:\n",
    "    bwlimidx = int((bwlim * deltaTMinA) + 1)\n",
    "    deltaF = 1./deltaTMinA*channels_per_tile\n",
    "    channels_per_tile = int(channels_per_tile)\n",
    "    \n",
    "    #get spectrogram with time step deltaTmin (no tile summing). \n",
    "    #The rows of Sxx are the frequencies and the columns the time segments\n",
    "    fx,tx,Sxx = signal.spectrogram(data_arr,\n",
    "                                   fs = FSamp,\n",
    "                                   nperseg = n_samp_per_seg,\n",
    "                                   noverlap = dtoverlap,\n",
    "                                   scaling ='spectrum',\n",
    "                                   mode = 'psd',\n",
    "                                   window = window)\n",
    "        \n",
    "#         print(\"Length of fx: {}\".format(np.size(fx)))\n",
    "#         print(\"Number of rows for Sxx: {}\".format(len(Sxx)))\n",
    "#         print(\"Number of columns for Sxx: {}\".format(len(Sxx[0])))\n",
    "    \n",
    "    #Reshape spectrogram to exclude frequencies above the bandwidth limit, bwlim\n",
    "    Sxx = Sxx[1:bwlimidx,:]\n",
    "    fx = fx[1:bwlimidx]\n",
    "    \n",
    "    if show_intermediate: #this is the initial spectrogram with no tiles summed and no data whitening\n",
    "        show_initial_spec(ep_station,tx,fx,Sxx,logplot,normalized = False)\n",
    "    \n",
    "    #Sxx shape: (f,t)\n",
    "    #get average PSD\n",
    "    Sk = np.nanmean(Sxx,axis=1)\n",
    "        \n",
    "    #divide each frequency tile by the average PSD at that frequency\n",
    "    fullSk = np.outer(Sk, np.ones(tx.shape))\n",
    "    SxxNormed = Sxx/fullSk\n",
    "    \n",
    "    if show_intermediate:\n",
    "        print(\"Average PSD: \")\n",
    "        show_avg_psd(ep_station,fx,Sk)\n",
    "        #Calculate the average normalized PSD; should fluctuate around 1 by construction. It is not used anywhere, just as a check\n",
    "        Sk_normed = np.nanmean(SxxNormed,axis=1)\n",
    "        print(\"Averaged Normalized PSD: \")\n",
    "        show_avg_psd(ep_station,fx,Sk_normed)\n",
    "    \n",
    "    if show_intermediate: #this is the initial normalized spectrogram with no tiles summed\n",
    "        show_initial_spec(ep_station,tx,fx,SxxNormed,logplot,normalized = True)\n",
    "   \n",
    "    #Print out entire spectrogram - It's big, so keep the if False unless you really want it...\n",
    "    if False:\n",
    "        print(\"fullSk\")\n",
    "        for i in range(len(fullSk)):\n",
    "            for j in range(len(fullSk[0])):\n",
    "                print (format('%.3f'%fullSk[i][j])), \n",
    "            print(\"\\n\")\n",
    "    \n",
    "    #sum up the appropriate number of small time and frequency tiles to get the desired tile size    \n",
    "    TF0 = 2*np.sum(SxxNormed[:,:int(nTtiles*segments_per_tile)].reshape(int(nChannels),nTtiles,segments_per_tile), axis = -1)\n",
    "    TFnoAvg = np.sum(Sxx[:,:int(nTtiles*segments_per_tile)].reshape(int(nChannels),nTtiles,segments_per_tile), axis = -1)\n",
    "\n",
    "    if makeplot: \n",
    "        #make a plot of the spectrogram\n",
    "        plotSummedSpec(ep_station, ts_data, TF0, tLim, nTtiles, deltaT, bwlim, nChannels, deltaF, logplot)\n",
    "        #calculate the reduced chi squared value representing how well the data follow a chisquared distribution with 2*dt*df degrees of freedom. \n",
    "        #This is not indended for use in flagging potential events\n",
    "        TFSane = TF0[~np.isnan(2.*TF0)]\n",
    "            \n",
    "        chsqr = GetChisqr(TFSane, dt = deltaT, df = deltaF, binw = 64, showplot = True)\n",
    "\n",
    "    return TFnoAvg, TF0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns both \"up\" and \"down\" frequency summed spectrograms plus the normalized and unnormalized spectrograms \n",
    "\n",
    "def EPI(ts_data,\n",
    "        Sxx, \n",
    "        SxxNormed,\n",
    "        segments_per_tile = 1, \n",
    "        channels_per_tile = 2,\n",
    "        deltaTMinA = 1.0,\n",
    "        deltaFmin = 1.0,\n",
    "        ep_station = 'test', \n",
    "        bwlim = 100.0,\n",
    "        makeplot = False,\n",
    "        show_intermediate = False, \n",
    "        logplot = True\n",
    "      ):\n",
    "    \n",
    "    deltaTMinA = float(deltaTMinA)\n",
    "    tLim = np.size(ts_data)/FSamp\n",
    "    data_arr = np.array(ts_data.value)\n",
    "\n",
    "    #time:\n",
    "    total_size = data_arr.size   \n",
    "    nsegments = Sxx.shape[1]\n",
    "    nTtiles = nsegments/segments_per_tile\n",
    "    deltaT = segments_per_tile*deltaTMinA\n",
    "       \n",
    "    #frequency:\n",
    "    deltaF = deltaFmin*channels_per_tile\n",
    "        \n",
    "    # Sxx shape: (f,t)\n",
    "    # SxxNormed shape: (f,t)\n",
    "\n",
    "    nsegments = int(nsegments)\n",
    "    nTtiles = int(nTtiles)\n",
    "    segments_per_tile = int(segments_per_tile)\n",
    "    channels_per_tile = int(channels_per_tile)\n",
    "\n",
    "    if show_intermediate: #this is the initial spectrogram with no tiles summed and no data whitening\n",
    "        tx = np.arange(0., tLim+deltaTMinA, deltaTMinA)\n",
    "        fx = np.arange(deltaFmin, bwlim+deltaFmin, deltaFmin)\n",
    "        show_initial_spec(ep_station,tx,fx,Sxx,logplot)\n",
    "        \n",
    "    #sum up the appropriate number of small time and frequency tiles to get the desired tile size \n",
    "    TF1 = np.sum((SxxNormed[:nFChannelsU*channels_per_tile, :nTtiles*segments_per_tile]).reshape((nFChannelsU,channels_per_tile, nTtiles, segments_per_tile)), axis = (-1,1))\n",
    "    TF2 = np.sum((SxxNormed[1:nFChannelsD*channels_per_tile+1, :nTtiles*segments_per_tile]).reshape((nFChannelsD,channels_per_tile, nTtiles, segments_per_tile)), axis = (-1,1))\n",
    "\n",
    "#    Sum frequency channels and time segments\n",
    "    TF0 = np.sum(SxxNormed[:,:nTtiles*segments_per_tile].reshape(int(nChannels),nTtiles,segments_per_tile), axis = -1)\n",
    "    TFnoAvg = np.sum(Sxx[:,:nTtiles*segments_per_tile].reshape(int(nChannels),nTtiles,segments_per_tile), axis = -1)\n",
    "    \n",
    "    #calculate the reduced chi squared value representing how well the data follow a chisquared distribution with 2*dt*df degrees of freedom. \n",
    "    #This is not indended for use in flagging potential events\n",
    "    if makeplot: \n",
    "        \n",
    "        fxBinup = np.linspace(deltaFmin, bwlim, nFChannelsU)\n",
    "        fxBindn = np.linspace(2.*deltaFmin, bwlim, nFChannelsD)\n",
    "        tx1 = np.linspace(0, tLim, nTtiles + 1)\n",
    "        TFSane = TF1[~np.isnan(TF1)]\n",
    "        chsqr = GetChisqr(TFSane, dt = deltaT, df = deltaF, binw = 64, showplot = True)\n",
    "\n",
    "        #make a plot of the spectrogram\n",
    "        f, (a0, a1) = plt.subplots(2,1, gridspec_kw = {'height_ratios':[4,1]},figsize=(12,8),sharex=True)\n",
    "        tme = np.linspace(0,tLim,np.size(ts_data))\n",
    "        a1.plot(tme,ts_data)\n",
    "        if logplot == True:\n",
    "            im1 = a0.pcolormesh(tx1,fxBinup,TF1, norm = matplotlib.colors.LogNorm())\n",
    "        else:\n",
    "            im1 = a0.pcolormesh(tx1,fxBinup,TF1)\n",
    "        a1.set_xlabel('time (s)')\n",
    "        a1.set_ylabel('amplitude (pT)')\n",
    "        a0.set_ylabel('freq (Hz)')\n",
    "        a0.set_yscale('symlog',nonposy = 'clip')\n",
    "        a0.grid(False)\n",
    "        a0.set_title(str(ep_station)+' Excess Power: Delta T = '+ str(deltaT)+' s. Delta f = '+ str(deltaF)+' Hz. ')\n",
    "        axs = [a0,a1]\n",
    "        f.colorbar(im1,ax=axs)\n",
    "        plt.show()\n",
    "\n",
    "    return TF1, TF2, TFnoAvg, TF0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the spectrogram using a masking array to exclude points when calculating the average PSD\n",
    "\n",
    "def EPII(ts_data,\n",
    "         deltaT,\n",
    "         fx,\n",
    "         Sxx0,\n",
    "         Sxxmask,\n",
    "         segments_per_tile,\n",
    "         channels_per_tile,\n",
    "         ep_station = 'test',\n",
    "         bwlim = 100.0,\n",
    "         makeplot = True,\n",
    "         show_intermediate = True, \n",
    "         logplot = True\n",
    "        ):\n",
    "\n",
    "   #time:\n",
    "    nTtiles = Sxxmask.shape[-1]\n",
    "    total_time = nTtiles*deltaT \n",
    "    \n",
    "    #frequency:\n",
    "    deltaFmin = fx[1]-fx[0]\n",
    "    deltaF = deltaFmin*channels_per_tile\n",
    "    #nChannels = Sxxmask.shape[0]\n",
    "    #nFChannelsU = (nChannels)/channels_per_tile\n",
    "    #nFChannelsD = (nChannels-1)/channels_per_tile\n",
    "    \n",
    "    if show_intermediate or makeplot:\n",
    "        tx = np.arange(0., total_time+deltaT, deltaT)\n",
    "        fxBinup = np.linspace(deltaFmin, bwlim, nFChannelsU)\n",
    "        fxBindn = np.linspace(2.*deltaFmin, bwlim, nFChannelsD)  \n",
    "    \n",
    "    saneData = np.ma.copy(Sxx0)    \n",
    "    saneData.mask = Sxxmask\n",
    "    \n",
    "    nTtiles =  int(nTtiles)\n",
    "    #nFChannelsU = int(nFChannelsU)\n",
    "    #nFChannelsD = int(nFChannelsD)  \n",
    "    segments_per_tile = int(segments_per_tile)\n",
    "    channels_per_tile = int(channels_per_tile)\n",
    "    \n",
    "    #if show_intermediate: #this is the initial spectrogram with no tiles summed and no data whitening\n",
    "        #show_initial_spec(tx,fx,saneData,False)\n",
    "   \n",
    "    nsegments_valid = np.ma.count(saneData, axis = -1)*segments_per_tile\n",
    "    if np.any(nsegments_valid == 0):\n",
    "        saneData.mask[nsegments_valid == 0,:] = 0\n",
    "\n",
    "    #get average PSD\n",
    "    Sk = np.nanmean(saneData, axis = 1)/segments_per_tile\n",
    "    if show_intermediate:\n",
    "        plt.title(\"average PSD\")\n",
    "        plt.ylabel(\"average PSD\")\n",
    "        plt.xlabel(\"frequency\")\n",
    "        plt.plot(fx,Sk)\n",
    "        plt.show()\n",
    "            \n",
    "    #divide each frequency tile by the average PSD at that frequency\n",
    "    fullSk = np.outer(Sk,np.ones(nTtiles))\n",
    "    SxxNormed = Sxx0/fullSk\n",
    "\n",
    "    TF1 = 2.*np.sum((SxxNormed[:nFChannelsU*channels_per_tile]).reshape((nFChannelsU,channels_per_tile, nTtiles)),axis = (1))\n",
    "    TF2 = 2.*np.sum((SxxNormed[1:nFChannelsD*channels_per_tile+1]).reshape((nFChannelsD,channels_per_tile, nTtiles)),axis = (1))\n",
    "\n",
    "    if show_intermediate and makeplot==False:\n",
    "        figure, axs = plt.subplots(2,1, figsize = (9,10))\n",
    "        if logplot:\n",
    "            im1 = axs[0].pcolormesh(tx,fxBinup,TF1,norm = matplotlib.colors.LogNorm())\n",
    "        else: \n",
    "            im1 = axs[0].pcolormesh(tx,fxBinup,TF1)\n",
    "        axs[0].set_xlabel('time (s)')\n",
    "        axs[0].set_ylabel('freq (Hz)')\n",
    "        axs[0].set_title(str(ep_station) + 'sum up Excess Power: Delta T = '+ str(deltaT)+' s. Delta f = '+ str(deltaF)+' Hz. ')\n",
    "        axs[0].grid(False)\n",
    "        figure.colorbar(im1, ax = axs[0])\n",
    "        axs[0].set_yscale('symlog',nonposy = 'clip')    \n",
    "        if logplot:\n",
    "            im2 = axs[1].pcolormesh(tx,fxBindn,TF2,norm = matplotlib.colors.LogNorm())\n",
    "        else: \n",
    "            im2 = axs[1].pcolormesh(tx,fxBindn,TF2)\n",
    "        axs[1].set_title(str(ep_station) + 'sum down Excess Power: Delta T = '+ str(deltaT)+' s. Delta f = '+ str(deltaF)+' Hz. ')\n",
    "        axs[1].set_xlabel('time (s)')\n",
    "        axs[1].set_ylabel('freq (Hz)')\n",
    "        axs[1].grid(False)\n",
    "        figure.colorbar(im2,ax = axs[1])\n",
    "        axs[1].set_yscale('symlog',nonposy = 'clip') \n",
    "        plt.show()\n",
    "        \n",
    "    if makeplot: \n",
    "        TFSane = TF1[~np.isnan(TF1)]\n",
    "        chsqr = GetChisqr(TFSane, dt = deltaT, df = deltaF, binw = 64, showplot = True)\n",
    "\n",
    "        #make a plot of the spectrogram\n",
    "        f, (a0, a1) = plt.subplots(2,1, gridspec_kw = {'height_ratios':[4,1]},figsize=(9,6),sharex=True)\n",
    "        tme = np.linspace(0,total_time,np.size(ts_data))\n",
    "        a1.plot(tme,ts_data)\n",
    "        if logplot == True:\n",
    "            im1 = a0.pcolormesh(tx,fxBinup,TF1, norm = matplotlib.colors.LogNorm())\n",
    "        else:\n",
    "            im1 = a0.pcolormesh(tx,fxBinup,TF1)\n",
    "        a1.set_xlabel('time (s)')\n",
    "        a1.set_ylabel('amplitude (pT)')\n",
    "        a0.set_ylabel('freq (Hz)')\n",
    "        a0.set_yscale('symlog',nonposy = 'clip')\n",
    "        a0.set_title(str(ep_station)+' Excess Power: Delta T = '+ str(deltaT)+' s. Delta f = '+ str(deltaF)+' Hz. ')\n",
    "        a0.grid(False)\n",
    "        axs = [a0,a1]\n",
    "        f.colorbar(im1,ax=axs)\n",
    "        plt.show()\n",
    "    return TF1, TF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates spectrogram with average PSD subtraced\n",
    "\n",
    "def EPIII(deltaT,\n",
    "          fx,\n",
    "          Sxx,\n",
    "          segments_per_tile,\n",
    "          channels_per_tile,\n",
    "          Sxxmask,         \n",
    "          ep_station = 'test',\n",
    "          bwlim = 100.,\n",
    "          makeplot = True,\n",
    "          show_intermediate = True,\n",
    "          logplot = True,\n",
    "          subtract = True\n",
    "        ):\n",
    "\n",
    "    #time:\n",
    "#     deltaT = tx[1]-tx[0]\n",
    "    nTtiles = Sxxmask.shape[-1]\n",
    "    total_time = nTtiles*deltaT \n",
    "    \n",
    "    #frequency:\n",
    "    deltaFmin = fx[1]-fx[0]\n",
    "    deltaF = deltaFmin*channels_per_tile\n",
    "    #nChannels = Sxxmask.shape[0]\n",
    "    #nFChannelsU = (nChannels)/channels_per_tile\n",
    "    #nFChannelsD = (nChannels-1)/channels_per_tile\n",
    "    \n",
    "#     Sxxmask2 = np.nonzero(Sxxmask)\n",
    "    saneData = np.ma.copy(Sxx)   \n",
    "#     saneData[np.isnan(saneData)] = np.ma.masked\n",
    "#     saneData[Sxxmask2] = np.ma.masked\n",
    "    saneData.mask = Sxxmask\n",
    "    nTtiles =  int(nTtiles)\n",
    "    #nFChannelsU = int(nFChannelsU)\n",
    "    #nFChannelsD = int(nFChannelsD) \n",
    "    \n",
    "    if show_intermediate or makeplot:\n",
    "        fxBinup = np.linspace(deltaFmin, bwlim, nFChannelsU)\n",
    "        fxBindn = np.linspace(2.*deltaFmin, bwlim, nFChannelsD) \n",
    "    \n",
    "    if False: #show_intermediate:\n",
    "        tx = np.arange(0., total_time+deltaT, deltaT)\n",
    "        f0, ax = plt.subplots(1,figsize=(9,5))\n",
    "        if logplot == True:\n",
    "            im = ax.pcolormesh(tx,fx,saneData,norm = matplotlib.colors.LogNorm())\n",
    "        else:\n",
    "            im = ax.pcolormesh(tx,fx,saneData)\n",
    "        ax.set_yscale('symlog',nonposy = 'clip')\n",
    "        ax.grid(False)\n",
    "        ax.set_xlabel('time (s)')\n",
    "        ax.set_ylabel('freq (Hz)')\n",
    "        ax.set_title('Final spectrgram before subtracting avg PSD')\n",
    "        f0.colorbar(im,ax=ax)\n",
    "        plt.show()  \n",
    "    \n",
    "    nsegments_valid = np.ma.count(saneData, axis = 1)\n",
    "    \n",
    "    #get average PSD\n",
    "    Sk = np.nanmean(saneData,axis = 1)\n",
    "    Sk[nsegments_valid == 0] = 0.\n",
    "    if show_intermediate:\n",
    "        show_avg_psd(ep_station,fx,Sk)\n",
    "            \n",
    "    fullSk = np.outer(Sk, np.ones(nTtiles))\n",
    "    if subtract:\n",
    "        SxxSubtracted = (Sxx - fullSk)\n",
    "    \n",
    "    else: \n",
    "        SxxSubtracted = Sxx\n",
    "    \n",
    "    TFu = 2.*np.sum((SxxSubtracted[:nFChannelsU*channels_per_tile]).reshape((nFChannelsU,channels_per_tile, nTtiles)),axis = (1))\n",
    "    TFd = 2.*np.sum((SxxSubtracted[1:nFChannelsD*channels_per_tile+1]).reshape((nFChannelsD,channels_per_tile, nTtiles)),axis = (1))\n",
    "\n",
    "    TFNSu = 2.*np.sum((Sxx[:nFChannelsU*channels_per_tile]).reshape((nFChannelsU,channels_per_tile, nTtiles)),axis = (1))\n",
    "    TFNSd = 2.*np.sum((Sxx[1:nFChannelsD*channels_per_tile+1]).reshape((nFChannelsD,channels_per_tile, nTtiles)),axis = (1))\n",
    "\n",
    "#     if subtract:\n",
    "#         TFu[TFu<0] = 0.\n",
    "#         TFd[TFd<0] = 0.\n",
    "    TFu = TFu/segments_per_tile\n",
    "    TFNSu = TFNSu/segments_per_tile\n",
    "    TFd = TFd/segments_per_tile\n",
    "    TFNSd = TFNSd/segments_per_tile\n",
    "    if show_intermediate:\n",
    "        figure, ax1 = plt.subplots(1,1, figsize=(9,5))\n",
    "        if logplot:\n",
    "            im = ax1.pcolormesh(tx,fxBinup,TFu,norm = matplotlib.colors.LogNorm())\n",
    "        else: \n",
    "            im = ax1.pcolormesh(tx,fxBinup,TFu)\n",
    "        ax1.set_xlabel('time (s)')\n",
    "        ax1.set_ylabel('freq (Hz)')\n",
    "        ax1.set_title(str(ep_station)+'Subtracted Spectrogram: Delta T = '+ str(deltaT)+' s. Delta f = '+ str(deltaF)+' Hz. ')\n",
    "        ax1.grid(False)\n",
    "        figure.colorbar(im,ax = ax1)\n",
    "        ax1.set_yscale('symlog',nonposy = 'clip')    \n",
    "        plt.show()\n",
    "\n",
    "#         plt.plot(fxBinup, np.nanmean(TFu, axis = 1))\n",
    "#         plt.show()\n",
    "#         plt.plot(fxBindn, np.nanmean(TFd, axis = 1))\n",
    "#         plt.show()\n",
    "    return TFu, TFd, TFNSu, TFNSd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flagEvents(maskIXUA, maskIXDA, eventSpecA, chanPerTileA):\n",
    "    \n",
    "    eventSpecR = np.copy(eventSpecA)\n",
    "    for i in range(0,maskIXUA[0].size):\n",
    "        idxf = np.arange((maskIXUA[0])[i]*chanPerTileA, ((maskIXUA[0])[i] + 1)*chanPerTileA)\n",
    "        idxt = np.array([maskIXUA[-1][i]]*chanPerTileA)\n",
    "        eventSpecR[idxf,idxt] = 1\n",
    "    for i in range(0,maskIXDA[0].size):\n",
    "        idxf = np.arange((maskIXDA[0])[i]*chanPerTileA+1, ((maskIXDA[0])[i] + 1)*chanPerTileA+1)\n",
    "        idxt = np.array([maskIXDA[-1][i]]*chanPerTileA)\n",
    "        eventSpecR[idxf,idxt] = 1\n",
    "        \n",
    "    return eventSpecR\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X2FromM(m, s, sig, D):\n",
    "    mu = np.einsum('jk, ik', D, m)\n",
    "    mu2 = ((mu-s)/sig)**2\n",
    "    chiSq = np.sum(mu2, axis = (-1))\n",
    "    return chiSq\n",
    "\n",
    "def X2(sFit, s, sig):\n",
    "    mu2 = ((sFit-s)/sig)**2\n",
    "    chiSq = np.sum(mu2, axis = (-1))\n",
    "    return chiSq\n",
    "\n",
    "\n",
    "def zeroPCalc(activeA, stdDevEventsA, eventsA , activeUncA):\n",
    "\n",
    "    e = 0\n",
    "    pZeroValsR = []\n",
    "    \n",
    "    eventTemp = np.copy(eventsA)\n",
    "    for sg, event in zip(np.transpose(stdDevEventsA), np.transpose(eventTemp)):\n",
    "        \n",
    "        event[event<0] = 0 \n",
    "        \n",
    "        # ignore insane/missing stations\n",
    "        activestations = np.nonzero(~np.isnan(event))\n",
    "        nactivestations = activestations[0].size\n",
    "        if nactivestations == 0:\n",
    "            print(\"no active stations\")\n",
    "            continue\n",
    "                        \n",
    "        #Redefining the following arrays allows a station to be ignored if there is missing or insane data\n",
    "        event = event[activestations]\n",
    "        sg = sg[activestations]\n",
    "        unc = activeUncA[activestations]\n",
    "                             \n",
    "        #Combine the statistical uncertainty with the calibration uncertainty\n",
    "        #Use sigma to propagate calibration unc if subtracted event is zero       \n",
    "        \n",
    "        calEvent = np.zeros(event.shape) #Uncertainty from calibration, propagated to event\n",
    "        calEvent[np.nonzero(event)] = event[np.nonzero(event)]\n",
    "        calEvent[event == 0.0] = sg[event == 0.0]\n",
    "        \n",
    "        calUnc = 2*unc*calEvent\n",
    "        delta = np.sqrt(sg**2 + calUnc**2) #Total uncertainty in event\n",
    "        \n",
    "        zeroEvent = np.zeros(np.size(event))\n",
    "        chiSqZero = X2(zeroEvent, event, delta)\n",
    "        \n",
    "        pZero = chi2.sf(chiSqZero, nactivestations)\n",
    "        pZeroValsR.append(pZero)   \n",
    "    \n",
    "#         print (\"event :\", event)\n",
    "#         print (\"event unc :\", sg )\n",
    "#         print (\"delts : \", delta)\n",
    "#         print (pZero)\n",
    "     \n",
    "        e+=1\n",
    "   \n",
    "    return pZeroValsR\n",
    "\n",
    "def eventUnc(asq, Nh2s2):\n",
    "    #asq2 = np.copy(asq)\n",
    "    #Defines the uncertainty based on the signal size\n",
    "    epsilon_p = np.sqrt(2*Nh2s2*asq - Nh2s2**2)\n",
    "    \n",
    "    #If the arguement of the sqrt is less than 0, just use the standard deviation??\n",
    "    epsilon_p[np.isnan(epsilon_p)] = Nh2s2[np.isnan(epsilon_p)]\n",
    "    \n",
    "    return epsilon_p\n",
    "\n",
    "\n",
    "\n",
    "def calculateEventUnc(nStationsA, MnNSA, maskIndex0A, eventsNSA, nEventsA, maskIndexA):\n",
    "\n",
    "    #Generate the event masks. \n",
    "    eventMask = np.zeros(MnNSA[0].shape)\n",
    "    eventMask[maskIndex0A]= 1\n",
    "    \n",
    "    #Counts the number of tiles that are not flagged in each frequency channel\n",
    "    nValid = np.count_nonzero(eventMask-1, axis = 1)\n",
    "    \n",
    "    #If there are fewer than 4 unmasked tiles, zero out the event mask                    \n",
    "    eventMask[nValid<3.5,:] = 0\n",
    "    \n",
    "    #initialize the uncertainty arrays\n",
    "    stdDevEventsR = np.zeros((nStationsA, nEventsA)) # uncertainties associated with each event\n",
    "    flaggedChanStdDev = np.zeros((nStationsA, nEventsA)) # stdev of the (masked) frequency channel for each event\n",
    "    #NOTE: shape = (frequency, time)\n",
    "    \n",
    "    for i in range(0, nStations):\n",
    "        # mask flagged tiles in the unsubtraced spectrogram,\n",
    "        # unless all of the tiles in a frequency band were flagged, \n",
    "        # in which case ignore flagged tiles for that frequency\n",
    "        \n",
    "        #The number of rows for Sxxmaskediu is equal to the number of frequency channels\n",
    "        #The number of columns is equal to the number of time segements         \n",
    "        Sxxmasked = np.ma.copy(MnNSA[i])\n",
    "        Sxxmasked.mask = eventMask\n",
    "        \n",
    "        # Calculate the standard deviation of the tiles in each frequency band for the unsubtracted spectrogram,\n",
    "        # excluding the flagged events\n",
    "        # The size of stdDev is equal to the number of frequency channels\n",
    "        stdDevU = np.nanstd(Sxxmasked, axis = 1)\n",
    "        \n",
    "        # get the values of N(h^2)(sigma^2) = sigma_PSD from the frequency bands of each event\n",
    "        # maskIndexA[0] is the list of frequency channels for each flagged event\n",
    "        flaggedChanStdDev[i,:nEventsA] = stdDevU[maskIndexA[0]]\n",
    "        \n",
    "       #plug in the event amplitude and sigma_PSD value to calculate the uncertainty\n",
    "    for i, (event, sigmaE) in enumerate(zip(np.transpose(eventsNSA),np.transpose(flaggedChanStdDev))):\n",
    "        \n",
    "        \n",
    "        tempStd = eventUnc(event/np.sqrt(segPerTile)/np.sqrt(chanPerTile), sigmaE)\n",
    "\n",
    "        tempStd[tempStd < sigmaE] = sigmaE[tempStd < sigmaE]\n",
    "        stdDevEventsR[:,i]  =  tempStd\n",
    "#         print (\"\\n\\n\",event)\n",
    "#         print (sigmaE)\n",
    "#         print(tempStd)\n",
    "\n",
    "    return stdDevEventsR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calFNegFunc(maskIndexA, expEventsA, nExpTilesA, numberFtilesA, numberTtilesA,PlotFnegMaps=False):\n",
    "\n",
    "        success = np.zeros((numberFtilesA, numberTtilesA))\n",
    "        success[maskIndexA] = 1\n",
    "\n",
    "        if PlotFnegMaps:\n",
    "            ts = np.arange(0., TLimit, tTileWidth)\n",
    "            figure, ax1 = plt.subplots(1, figsize = (8,5))\n",
    "            im = ax1.pcolormesh(ts, fx, 2.*success-expEventsA)\n",
    "            ax1.colorbar()\n",
    "            ax1.set_xlabel('Time (s)')\n",
    "            ax1.set_ylabel('Frequency (Hz)')\n",
    "            ax1.grid(False)\n",
    "            ax1.set_yscale('symlog', nonposy = 'clip')  \n",
    "            ax1.set_title('2* Detected Events - Expected Events')\n",
    "            plt.show()\n",
    "\n",
    "        success -= expEventsA\n",
    "\n",
    "        nFN = np.count_nonzero(success < -0.5)\n",
    "        if nExpTilesA > 0: nFN = float(nFN)/float(nExpTilesA)\n",
    "        return (1.-nFN)       \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def chisqFit(x,a,b,c):\n",
    "    \n",
    "    dMatrix = fitEventAmplitudes.var\n",
    "    sTemp = (np.matmul(dMatrix, np.array([a,b,c])))**2\n",
    "\n",
    "    return sTemp\n",
    "\n",
    "\n",
    "\n",
    "def fitEventAmplitudes(activeA, stdDevEventsA, eventsA, nEventsA, activeUncA, EPeventsA,thresholdA,concidentIndexA):\n",
    "    \n",
    "    Xf, Yf, Zf = initializeVectorSpace(activeA)  \n",
    "\n",
    "    e = 0\n",
    "    pValsR = []\n",
    "    pZeroValR= []\n",
    "    coinValR = []\n",
    "    consitencyIndex = np.zeros((nEventsA,activeA.size ))  \n",
    "    \n",
    "    mVectsR = np.zeros((nEventsA, 3))\n",
    "    sigmaMatrixR = np.zeros((nEventsA, 3, 3))\n",
    "     \n",
    "    for sg, event in zip(np.transpose(stdDevEventsA), np.transpose(eventsA)):\n",
    "\n",
    "        \n",
    "        # ignore insane/missing stations\n",
    "        activestations = np.nonzero(~np.isnan(event))\n",
    "        nactivestations = activestations[0].size\n",
    "        if nactivestations == 0:\n",
    "            print(\"no active stations\")\n",
    "            continue\n",
    "                        \n",
    "        #Redefining the following arrays allows a station to be ignored if there is missing or insane data\n",
    "        event = event[activestations]\n",
    "        sg = sg[activestations]\n",
    "        unc = activeUncA[activestations]\n",
    "                                            \n",
    "        X = Xf[activestations]\n",
    "        Y = Yf[activestations]\n",
    "        Z = Zf[activestations]\n",
    "        #copy of with with negative values \n",
    "        event0 = np.copy(event)\n",
    "\n",
    "        #Take the square root of the events so that we are dealing with amplitudes rather than power\n",
    "        #set the negative events as zeros\n",
    "        event[event<0] = 0.\n",
    "        sqrtEvent = np.sqrt(event)\n",
    "            \n",
    "        #Propagate the statistical uncertainty in the power to the amplitude\n",
    "        #If the subtracted event is zero, use the sqrt of the standard deviation as uncertainty.\n",
    "        deltaStat = np.zeros(event.shape)\n",
    "        deltaStat[np.nonzero(event)] = 0.5*sg[np.nonzero(event)]/np.sqrt(event[np.nonzero(event)])\n",
    "        deltaStat[event == 0.0] = np.sqrt(sg[event == 0.0])\n",
    "            \n",
    "        #Combine the statistical uncertainty with the calibration uncertainty\n",
    "        delta = np.sqrt(deltaStat**2+ ((sqrtEvent*unc)**2) )\n",
    "\n",
    "        X0 = X/delta\n",
    "        Y0 = Y/delta\n",
    "        Z0 = Z/delta\n",
    "        sqrtEvent0 = sqrtEvent/delta\n",
    "        \n",
    "        D = np.array([X,Y,Z])\n",
    "        D = np.transpose(D)\n",
    "        J = np.array([X0, Y0, Z0])\n",
    "        J = np.transpose(J)\n",
    "        U = np.matmul(J.T,J)\n",
    "\n",
    "        #Generate array of the sqrtEvents to test all sign combinations\n",
    "        Sfull = np.tile(sqrtEvent, (2**(nactivestations-1),1))\n",
    "        Snfull = np.tile(sqrtEvent0, (2**(nactivestations-1), 1))\n",
    "                              \n",
    "        #Generate array to generated all sign combinations\n",
    "        negatives = np.array(list(itertools.product(range(2), repeat = nactivestations)))\n",
    "\n",
    "        negatives = negatives[0:(2**(nactivestations-1))]\n",
    "                    \n",
    "        #Flip the signs on the sqrtEvents to test the different sign combinations                              \n",
    "        Snfull[np.nonzero(negatives)] = Snfull[np.nonzero(negatives)]*(-1.)   \n",
    "        Sfull[np.nonzero(negatives)] = Sfull[np.nonzero(negatives)]*(-1.)\n",
    "                        \n",
    "        B = np.einsum('kj, ik', J, Snfull)\n",
    "        uInv = scipy.linalg.inv(U)\n",
    "#       m = np.array(list(scipy.linalg.solve(U, b) for b in B)) \n",
    "        m = np.array([np.matmul(uInv, b) for b in B])\n",
    "       \n",
    "        chiSq = X2FromM(m, Sfull, delta, D)\n",
    "        bestChi2i = np.argmin(chiSq)                    \n",
    "        mFinal = m[bestChi2i]\n",
    "        mVectsR[e] = mFinal                         \n",
    "        sigmaMatrixR[e] = uInv\n",
    "        \n",
    "        \n",
    "#         p = chi2.sf(chiSq[bestChi2i], nactivestations-3 ) \n",
    "#         eventFit = np.matmul(D,mFinal)**2\n",
    "#         chiSqEvent = X2(eventFit,event,sg)\n",
    "#         pEvent = chi2.sf(chiSqEvent, nactivestations-3)\n",
    "\n",
    "        xdata = np.arange(0,nactivestations)\n",
    "        fitEventAmplitudes.var = D\n",
    "        \n",
    "\n",
    "        mParam, mParam_cov = optimize.curve_fit(chisqFit, xdata, event0, sigma = sg,p0= mFinal,absolute_sigma =True, maxfev = 10000 )   \n",
    "        signalFit = (np.matmul(D, mParam))**2\n",
    "#         pSignal = chi2.sf(X2(event0,signalFit,sg), nactivestations-3)\n",
    "#         pSignalZero = chi2.sf(X2(event0,np.zeros(nactivestations),sg), nactivestations)\n",
    "\n",
    "        epFit = ((EPeventsA[e]-128)*signalFit/event0)+128\n",
    "\n",
    "        for k in range(event0.size):\n",
    "            consitencyIndex[e][k] = ( epFit[k] >thresholdA ) \n",
    "\n",
    "#         pCoincidence = np.sum(consitencyIndex[e][concidentIndexA[e]==1]) \n",
    "\n",
    "        sp = event0/signalFit\n",
    "        delSp = sg/signalFit\n",
    "        spAvg = (np.sum(sp/(delSp**2)))/(np.sum(1/(delSp**2)))\n",
    "        delSpAvg = np.sqrt( 1/np.sum(1/(delSp**2)))\n",
    "        spX2 = np.sum( (sp-spAvg)**2/(delSp**2) )\n",
    "        pSp = chi2.sf(spX2, nactivestations-3)\n",
    "        \n",
    "        pValsR.append(pSp)\n",
    "        pZeroValR.append(spAvg/delSpAvg) #NOTE: pZeroValR is NOT the p-value for the zero amplitude case! It is the liklihood statistic!\n",
    "        \n",
    "        \n",
    "#         print (\"\\n\\n event #\",e+1)         \n",
    "#         print (\"\\n\\n event #\",e+1)          \n",
    "#         print(event0,signalFit,sp)\n",
    "        \n",
    "#         print (\"spAvg\",spAvg)\n",
    "#         print (\"delSpAvg\",delSpAvg)        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         pValsR.append(pSignal)\n",
    "#         pZeroValR.append(pSignalZero)\n",
    "#         coinValR.append(pCoincidence)  \n",
    "\n",
    "#         print (\"\\n\\n event # \",e+1)          \n",
    "#         print (\"S :\",event0)\n",
    "#         print (\"delS :\",sg)\n",
    "#         print (\"sFit :\",signalFit)\n",
    "#         print (\"|m| :\",np.linalg.norm(mParam))\n",
    "#         print (\"sp : \", sp)\n",
    "#         print (\"delSp :\",delSp)\n",
    "#         print (\"spAvg :\",spAvg)\n",
    "#         print (\"delSpAvg: \",delSpAvg)\n",
    "#         print (\"X2 :\",spX2,spAvg/delSpAvg )\n",
    "#         if np.linalg.norm(mParam) == 0:\n",
    "#             print (\"\\n\\n ahhhh m=0\",np.linalg.norm(mParam),delSp)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#         print(pSignal)\n",
    "#         print (active)\n",
    "#         print (\"e\",EPeventsA[e])\n",
    "#         epFit = ((EPeventsA[e]-128)*signalFit/event0)+128\n",
    "#         print (\"eFit\",epFit)\n",
    "\n",
    "#         print (concidentIndexA[e])\n",
    "#         print (consitencyIndex[e])\n",
    "#         print (pCoincidence)   \n",
    "\n",
    "\n",
    "#         if e<1:\n",
    "#             print (\"\\n\\n event #\",e+1)          \n",
    "#             print (\"S\",event0)\n",
    "#             print (\"delS\",sg)\n",
    "\n",
    "#             print (\"sFit\",signalFit)\n",
    "#             print(\"????\",X2(event0,signalFit,sg),pSignal)\n",
    "\n",
    "\n",
    "        e+=1\n",
    "              \n",
    "    return np.array(pValsR),np.array(pZeroValR)\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistency(activeA, stdDevEventsA, eventsA, maskIndexA, nEventsA, activeUncA, MnA, thresholdA,thA):\n",
    "\n",
    "\n",
    "    EPevents = np.ones((activeA.size, nEventsA))\n",
    "    concidentIndexA = np.zeros((activeA.size, nEventsA))    \n",
    "    \n",
    "    if nEventsA>0:    \n",
    "        for i,station in enumerate(activeA): \n",
    "            EPevents[i]   = (MnA[i])[maskIndexA]   \n",
    "            concidentIndexA[i][:] = MnA[i][maskIndexA]>thresholdA\n",
    "#         print (concidentIndexA)\n",
    "#     print (EPevents)\n",
    "\n",
    "    EPevents = np.transpose(EPevents)\n",
    "    concidentIndexA = np.transpose(concidentIndexA)\n",
    "\n",
    "\n",
    "    pValsR,pZeroValR = fitEventAmplitudes(activeA, stdDevEventsA, eventsA, nEventsA, activeUncA, EPevents,thresholdA,concidentIndexA)                \n",
    "\n",
    "#     passedCoin   = np.nonzero(coinValR > (nCoin - 0.5))[0] \n",
    "#     passedPCheck = np.nonzero((pValsR/pZeroValR) > pDistThreshold[th])[0]\n",
    "#     passedFinal  = np.intersect1d(passedCoin, passedPCheck)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    pValueDist[thA] = np.append(pValueDist[thA], pValsR)\n",
    "    pZeroValueDist[thA] = np.append(pZeroValueDist[thA], pZeroValR)\n",
    "    \n",
    "\n",
    "\n",
    "#     pCoinSpectR  = ((maskIndexA[0])[passedCoin],(maskIndexA[1])[passedCoin]) \n",
    "#     pFinalSpectR = ((maskIndexA[0])[passedFinal],(maskIndexA[1])[passedFinal]) \n",
    "        \n",
    "    \n",
    "#     print (\"passedPCheck :\", passedPCheck.size/pValsR.size)\n",
    "#     print (\"passedFinal:\", passedFinal.size/pValsR.size)\n",
    "        \n",
    "#     print (\"\\n\\n\\n\\n\\n\",\"coinValR: \",coinValR)\n",
    "#     print (\"passedCoin   = np.nonzero(coinValR > (nCoin - 0.5))[0] :\",passedCoin)\n",
    "#     print (\"pValsR \",pValsR)\n",
    "#     print (\"pValsR[coinValR> (nCoin - 0.5)]: \",pValsR[coinValR> (nCoin - 0.5)])\n",
    "#     print (\"pValsR[passedCoin]\",pValsR[passedCoin])\n",
    "#     print (pValsR[passedFinal])\n",
    "#     print (pValsR[np.intersect1d(passedCoin, passedPCheck)])\n",
    "#     return  pValsR,coinValR,pZeroValR \n",
    "    \n",
    "    \n",
    "#     return  pCoinSpectR,pFinalSpectR \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Code to Run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Global Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'test', 'test', 'test', 'test', 'test']\n"
     ]
    }
   ],
   "source": [
    "filt = False #Filter the data\n",
    "RealData = False #Use real data or Gaussian data\n",
    "RandomDays = False \n",
    "PlotFigs = False #Generate plots during analysis\n",
    "PlotEventMaps = False #Generates plots of the event maps\n",
    "Check = False\n",
    "\n",
    "FSamp = 512. #Sample Frequency\n",
    "BWLim = 100. #Bandwidth limit\n",
    "FNyq = FSamp/2.\n",
    "\n",
    "\n",
    "ShiftTime = 500 #Number of seconds to time shift each station\n",
    "\n",
    "fullStationList = ['hefei01', 'lewisburg01','mainz01','oberlin01','krakow01','beijing01','berkeley02','daejeon01' ,'moxa01' ]\n",
    "\n",
    "#Fractional Calibration Uuncertainties in Percentage\n",
    "#np.array([0.0,35.0,4.4,0.0,2.6,0,129.9,18.2,0,72,9.8,0,1.3]) \n",
    "fullCalUnc = np.zeros(len(fullStationList))\n",
    "\n",
    "#Bandwidth correction \n",
    "fullBandCorr = [np.ones(100)]*len(fullStationList)\n",
    "\n",
    "# Spin coupling uncertainties and correction\n",
    "fullSpinCorr =  [1.]*len(fullStationList)\n",
    "fullSpinUnc  =  np.zeros(len(fullStationList))\n",
    "\n",
    "#Turns fractional uncertainties into multiplicative factor\n",
    "fullUnc = np.sqrt(fullCalUnc**2 +fullSpinUnc**2 )/100.0\n",
    "\n",
    "if RealData:\n",
    "    stationList = fullStationList\n",
    "else:\n",
    "    numberOfStations = 6\n",
    "    stationList = []\n",
    "    for i in range(0, numberOfStations): stationList.append('test')        \n",
    "    stations = np.array(stationList) \n",
    "    \n",
    "print(stationList)    \n",
    "    \n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.style.use(\"seaborn-white\")\n",
    "# da = np.random.randn(1000)\n",
    "# x1 = np.random.normal(0, 0.8, 1000)\n",
    "# x2 = np.random.normal(-2, 1, 1000)\n",
    "# x3 = np.random.normal(3, 2, 1000)\n",
    "# # plt.hist(da,bins= 50, alpha=0.5,color='steelblue')\n",
    "# # plt.hist(da,bins= 50, alpha=0.5,color='steelblue')\n",
    "# # plt.hist(da,bins= 50, alpha=0.5,color='steelblue')\n",
    "# kwargs = dict(histtype='stepfilled', alpha=0.3, bins=40)\n",
    "# plt.hist(x1, **kwargs)\n",
    "# plt.hist(x2, **kwargs)\n",
    "# plt.hist(x3, **kwargs);\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "imshow() got multiple values for argument 'cmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3ae1fd9ffa1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Blues'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'counts in bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: imshow() got multiple values for argument 'cmap'"
     ]
    }
   ],
   "source": [
    "mean = [0, 0]\n",
    "cov = [[1, 1], [1, 2]]\n",
    "x, y = np.random.multivariate_normal(mean, cov, 10000).T\n",
    "plt.imshow(x, y, bins=30, cmap='Blues')\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('counts in bin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the time interval considered, the time block length and generate the time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ndates: 1\n",
      "# of starts: 1\n",
      "['2020-02-18-19-00-40'] ['2020-02-18-19-34-48']\n",
      "[0.]\n",
      "2020-02-18 19:34:48\n"
     ]
    }
   ],
   "source": [
    "startstr = '2020-02-18-19-00-40'\n",
    "# endstr = '2020-02-20-18-14-00'\n",
    "\n",
    "WindowLength = 2048 #Block of time for each spectrogram 2048 s\n",
    "ndates = 1#Number of windows used 40\n",
    "\n",
    "#Generate windows for the analysis\n",
    "windowStarts = []\n",
    "windowEnds = []\n",
    "secWindowStarts = np.arange(0., ndates*WindowLength, WindowLength)\n",
    "print(\"\\n ndates: {}\".format(ndates))\n",
    "print(\"# of starts: {}\".format(secWindowStarts.size))\n",
    "starttime = datetime.strptime(startstr,'%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "for i in range(ndates):\n",
    "    startstme = starttime + timedelta(seconds = secWindowStarts[i])\n",
    "    windowStarts.append(startstme.strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "    endstme = starttime + timedelta(seconds = secWindowStarts[i] + WindowLength)\n",
    "    windowEnds.append(datetime.strftime(endstme,'%Y-%m-%d-%H-%M-%S'))\n",
    "#     print(station_list)\n",
    "\n",
    "TLimit = WindowLength\n",
    "print (windowStarts,windowEnds)\n",
    "print(secWindowStarts)\n",
    "print(endstme)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the thresholds, the tiles size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cut offs for consistency checks\n",
    "mThreshold = 3 #m-Check: Number of sigma away from zero required\n",
    "pThreshold = 0.75 #p-check: Probability required from fit -- Need at least 1% prob that fit is consistent\n",
    "pZeroThreshold = 0.3 #p-Zero-check: Probability that fit is consistent with zero -- fpr pZeroThresold = 0.3, need less than 30% prob that data are consistent with zero\n",
    "\n",
    "nCoin = 4 # Number of stations required for coincidence\n",
    "\n",
    "#value used to calculate the prob of excess power greater than beta\n",
    "beta = 0.003\n",
    "sigma = 4 #Used for initial guess to find the root of the Eq. solved to find beta\n",
    "\n",
    "# Set EP tile parameters\n",
    "deltaTMin = 1.0 #minimum time segement length in seconds\n",
    "imaxt = 5 #sets max number of tiles summed 2^imaxt\n",
    "imint = 5 #sets min number of tiles summed 2^imint\n",
    "imaxf = 1 #sets max number of frequencies summed 2^imaxf\n",
    "\n",
    "#Set the maximum and minimum ranges for the excess power checks for different number of tiles summed\n",
    "# thresholdmins = [6.0, 15.0, 25.0, 20.0, 190.0, 128.0, 290.0 , 560.0 ]\n",
    "# thresholdmaxs = [15.0, 30.0, 40.0, 55.0, 190.0, 152.0, 330.0, 610.0]\n",
    "# nThreshs = 25   #number of excess power thresholds considered\n",
    "\n",
    "\n",
    "thresholdmins = [6.0, 15.0, 25.0, 20.0, 190.0, 122.0, 290.0 , 560.0 ]\n",
    "thresholdmaxs = [15.0, 30.0, 40.0, 55.0, 190.0, 152.0, 330.0, 610.0]\n",
    "nThreshs = 11   #number of excess power thresholds considered\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Done setting parameters\n",
    "# itxs = np.arange(imint,imaxt+1,1)\n",
    "tsums = np.array([2**n for n in range(imint,imaxt+1)]) #List of number of tiles summed\n",
    "ntsums = tsums.size #Number of different tile sums\n",
    "segPerTileMin = tsums[0] #First time sum\n",
    "segPerTileMax = tsums[-1] #Last time sum\n",
    "\n",
    "chanPerTile = 2**imaxf #Number of frequency tiles summed\n",
    "fTileWidth = chanPerTile*(1/deltaTMin)\n",
    "fs = np.arange(1./deltaTMin, BWLim/deltaTMin +1, 1./deltaTMin) #Sets frequeny range   \n",
    "nChannels = (BWLim+1) * deltaTMin - 1\n",
    "nFChannelsU = int( np.floor(nChannels/chanPerTile) ) #Creates frequncy channels for \"up\" spectrogram\n",
    "nFChannelsD = int( np.floor((nChannels-1)/chanPerTile) ) #Creates frequncy channels for \"down\" spectrogram\n",
    "fsU = np.arange(1./deltaTMin, nFChannelsU*fTileWidth+fTileWidth-1, fTileWidth) #frequeny range for \"up\" spectrogram\n",
    "fsD = np.arange(2./deltaTMin, nFChannelsD*fTileWidth+fTileWidth+1, fTileWidth)   #frequeny range for \"down\" spectrogram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tsums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[122., 125., 128., 131., 134., 137., 140., 143., 146.,\n",
       "        149., 152.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = np.zeros((ntsums, nThreshs))\n",
    "for i,n in enumerate(np.arange(imint,imaxt+1,1)):\n",
    "    thresholdmax = thresholdmaxs[n]\n",
    "    thresholdmin = thresholdmins[n]\n",
    "    thresholds[i,:] = np.linspace(thresholdmin, thresholdmax, nThreshs)\n",
    "thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pDistThreshold = np.array([0.39, 0.34, 0.48, 0.54, 0.61, 0.7 , 0.94, 1.44, 1.32,\n",
    "#        5.91, 10.  ])\n",
    "\n",
    "pDistThreshold = np.empty(nThreshs)\n",
    "pValueDist = np.empty(nThreshs, dtype = np.ndarray) \n",
    "pZeroValueDist = np.empty(nThreshs, dtype = np.ndarray) \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the number of trials for the False Positive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[None None None None None None None None None None None]\n",
      "[None None None None None None None None None None None]\n",
      "[122. 125. 128. 131. 134. 137. 140. 143. 146. 149. 152.]\n"
     ]
    }
   ],
   "source": [
    "# number of the random shuffled data trials\n",
    "nTrials = 2\n",
    "print(nThreshs)\n",
    "print(pValueDist)\n",
    "print(pZeroValueDist)\n",
    "print(pDistThreshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Excess Power and Perform Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the data\n",
      "[[<TimeSeries([-0.32123966, -1.00490694, -0.57177355, ...,\n",
      "             -0.42010908, -0.80669468,  0.13039507]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 0.00195312 s>,\n",
      "            name=None,\n",
      "            channel=None)>, <TimeSeries([ 0.16280463, -1.71165328, -0.82566114, ...,\n",
      "             -1.553175  ,  1.13743504, -1.12100301]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 0.00195312 s>,\n",
      "            name=None,\n",
      "            channel=None)>, <TimeSeries([-0.29930825, -0.04609519,  1.04251365, ...,\n",
      "              0.20887614, -0.77115249,  0.2881757 ]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 0.00195312 s>,\n",
      "            name=None,\n",
      "            channel=None)>, <TimeSeries([-0.65918262,  2.1862369 ,  0.07185587, ...,\n",
      "              0.41375772,  0.42043184,  2.03472216]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 0.00195312 s>,\n",
      "            name=None,\n",
      "            channel=None)>, <TimeSeries([-0.74452772, -0.58880942,  0.30035373, ...,\n",
      "             -0.3777573 ,  1.36657677,  0.4542567 ]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 0.00195312 s>,\n",
      "            name=None,\n",
      "            channel=None)>, <TimeSeries([-1.32149504, -0.35917924, -0.96182561, ...,\n",
      "             -1.36849143,  1.12205634, -1.18731132]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 0.00195312 s>,\n",
      "            name=None,\n",
      "            channel=None)>]]\n",
      "[[<TimeSeries([1., 1., 1., ..., 1., 1., 1.]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 1. s>,\n",
      "            name=None,\n",
      "            channel=None)>, <TimeSeries([1., 1., 1., ..., 1., 1., 1.]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 1. s>,\n",
      "            name=None,\n",
      "            channel=None)>, <TimeSeries([1., 1., 1., ..., 1., 1., 1.]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 1. s>,\n",
      "            name=None,\n",
      "            channel=None)>, <TimeSeries([1., 1., 1., ..., 1., 1., 1.]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 1. s>,\n",
      "            name=None,\n",
      "            channel=None)>, <TimeSeries([1., 1., 1., ..., 1., 1., 1.]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 1. s>,\n",
      "            name=None,\n",
      "            channel=None)>, <TimeSeries([1., 1., 1., ..., 1., 1., 1.]\n",
      "            unit=Unit(dimensionless),\n",
      "            t0=<Quantity 0. s>,\n",
      "            dt=<Quantity 1. s>,\n",
      "            name=None,\n",
      "            channel=None)>]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "[masked_array(data=[--, 'lewisburg01', 'mainz01', --, --,\n",
      "                   'beijing01', 'oberlin01', 'krakow01',\n",
      "                   'hefei01'],\n",
      "             mask=[ True, False, False,  True,  True, False,\n",
      "                   False, False, False],\n",
      "       fill_value='N/A',\n",
      "            dtype='<U11')]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b884ab0d4985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m#MnND is unnormalized spectrogram, SxxN is the normalized spectrogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             MnND[i], SxxN[i] =  EP0(datalist[j][i],\n\u001b[0m\u001b[1;32m     87\u001b[0m                                     \u001b[0msegments_per_tile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegPerTileStart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                                     \u001b[0mchannels_per_tile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdeltaTMin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1828c95ef18f>\u001b[0m in \u001b[0;36mEP0\u001b[0;34m(ts_data, segments_per_tile, channels_per_tile, deltaTMinA, ep_station, bwlim, window, makeplot, show_intermediate, logplot)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmakeplot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m#make a plot of the spectrogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mplotSummedSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep_station\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTF0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtLim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnTtiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltaT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbwlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnChannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltaF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;31m#calculate the reduced chi squared value representing how well the data follow a chisquared distribution with 2*dt*df degrees of freedom.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m#This is not indended for use in flagging potential events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-bf873ef21c24>\u001b[0m in \u001b[0;36mplotSummedSpec\u001b[0;34m(stationA, tSDataA, tF0A, tLimitA, nTTilesA, deltaTA, bwlimA, nChanA, deltaFA, logplotA)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtLimitA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnTTilesA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mfx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltaFA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbwlimA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnChanA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridspec_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'height_ratios'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtLimitA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtSDataA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/numpy/core/function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of samples, %s, must be non-negative.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "nStationsAvg=0\n",
    "randomstation =[]\n",
    "fPosEP = np.zeros((fs.size, ntsums, nThreshs, ndates, nTrials)) #Initiallizes array for excess power false positives\n",
    "fPosCoin = np.zeros((fs.size, ntsums, nThreshs, ndates, nTrials))\n",
    "fPosP = np.zeros((fs.size, ntsums, nThreshs, ndates, nTrials)) #Initiallizes array for excess power & p-check false positives\n",
    "\n",
    "#Each interation of nTrials uses a different ordering of the stations to randomize the time shifting\n",
    "for z in range(nTrials):\n",
    "#     print (\"\\n\\n trial #\", z)\n",
    "    startStamp = datetime.now().strftime(\"%H:%M:%S\") \n",
    "    #Load Time Shuffled Data\n",
    "    datalist, sanitylist, fullUncList, fullSpinCorrList, fullBandCorrList, stations, nStationsAvg, startTimes, endTimes = LoadTimeShuffled( \n",
    "                                                                                              ndates,\n",
    "                                                                                              fullStationList,\n",
    "                                                                                              fullUnc,\n",
    "                                                                                              fullSpinCorr,\n",
    "                                                                                              fullBandCorr,\n",
    "                                                                                              nStationsAvg,\n",
    "                                                                                              realDataA = RealData,\n",
    "                                                                                              timeShiftA = False\n",
    "                                                                                            )\n",
    "    print(\"Here are the data\")\n",
    "    print(datalist)\n",
    "    print(sanitylist)\n",
    "    print(fullUncList)\n",
    "    print(fullSpinCorrList)\n",
    "    print(fullBandCorrList)\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    #Generate the threshold for different number of tiles summed assuming some desired confidence level, beta. \n",
    "    # and a Gaussian distribution. This is the threshold for the initial pass through the normalized spectrograms.\n",
    "    # The sigma is just used to set the initial guess for finding the roots. The beta sets the confidence level.\n",
    "    threshold0s = np.array([calculatecutoff(dofA = 2.*t*chanPerTile, \n",
    "                                            NstA = nStationsAvg, \n",
    "                                            nCoinA = nCoin, \n",
    "                                            betaA = beta, \n",
    "                                            sigmaA = sigma) \n",
    "                            for t in tsums])\n",
    "\n",
    "    #Generates the thresholds at which to calculate the false probability based on max and min thresholds.\n",
    "    thresholds = np.zeros((ntsums, nThreshs))\n",
    "    for i,n in enumerate(np.arange(imint,imaxt+1,1)):\n",
    "        thresholdmax = thresholdmaxs[n]\n",
    "        thresholdmin = thresholdmins[n]\n",
    "        thresholds[i,:] = np.linspace(thresholdmin, thresholdmax, nThreshs)\n",
    "\n",
    "    #Loop over the number of time windows\n",
    "    for j in range(0, ndates): \n",
    "        \n",
    "        startStamp2 = datetime.now().strftime(\"%H:%M:%S\") \n",
    "        \n",
    "        #Determine the number of active stations\n",
    "        print(stations)\n",
    "        active = stations[j].compressed()\n",
    "        nStations = active.size\n",
    "\n",
    "            \n",
    "        dataDelete, sanityDelete = GenerateNoise(TLimit, a = 10.0)\n",
    "        for i,station in enumerate(active):\n",
    "            if station == \"0001\":\n",
    "                datalist[j][i] = TimeSeries(dataDelete, sample_rate = FSamp)    \n",
    "\n",
    "        \n",
    "        activeUnc = np.copy(fullUncList[np.nonzero(stations[j].mask*(-1)+1)])\n",
    "        activeSpinCorr = np.copy(fullSpinCorrList[np.nonzero(stations[j].mask*(-1)+1)])\n",
    "        activeBwNnorm = np.copy(fullBandCorrList[np.nonzero(stations[j].mask*(-1)+1)])\n",
    "\n",
    "        #Initialize the arrays of spectrograms. The elements of the array correspond to the different stations\n",
    "        SxxN = np.empty(nStations, dtype = np.ndarray) #Normalized Spectrogram\n",
    "        Mnu0 = np.empty(nStations, dtype = np.ndarray) #\"Up\" Frequency Summed Spectrogram\n",
    "        Mnd0 = np.empty(nStations, dtype = np.ndarray) #\"Down\" Frequency Summed Spectrogram\n",
    "        MnND = np.empty(nStations, dtype = np.ndarray) #Unnormalized Spectrogram\n",
    "        \n",
    "        \n",
    "        MnSU = np.empty(nStations, dtype = np.ndarray)  #\"Up\" Subracted Spectrogram\n",
    "        MnSD = np.empty(nStations, dtype = np.ndarray)  #\"Down\" Subracted Spectrogram\n",
    "        MnNSU = np.empty(nStations, dtype = np.ndarray) #\"Up\" Unsubracted Spectrogram\n",
    "        MnNSD = np.empty(nStations, dtype = np.ndarray) #\"Down\" Unsubracted Spectrogram\n",
    "        \n",
    "        segPerTileStart = np.ceil(segPerTileMin/2.)\n",
    "\n",
    "        #Generate unnormalized and normalized initial spectrograms.\n",
    "        #The time tile size is equal to 1/2 the min time tile or the min tile size, deltaTMin\n",
    "        #No frequency channels are summed\n",
    "        #MnND is unnormalized spectrogram, SxxN is the normalized spectrogram\n",
    "        for i,station in enumerate(active):\n",
    "            MnND[i], SxxN[i] =  EP0(datalist[j][i],\n",
    "                                    segments_per_tile = segPerTileStart,\n",
    "                                    channels_per_tile = 1/deltaTMin,\n",
    "                                    deltaTMinA = deltaTMin,\n",
    "                                    ep_station = active[i],\n",
    "                                    makeplot = True,\n",
    "                                    show_intermediate = False\n",
    "                                   )\n",
    "\n",
    "    ############################################################  \n",
    "    ############################################################\n",
    "        tTileWidth = deltaTMin*segPerTileStart\n",
    "        \n",
    "        #Loop through all of the tile sum combinations being considered\n",
    "        for n, segPerTile in enumerate(tsums): \n",
    "            tTileWidthPrev = tTileWidth\n",
    "            tTileWidth = segPerTile*deltaTMin\n",
    "            numberTtiles = int(np.round(TLimit/tTileWidth))\n",
    "\n",
    "#              begin excess power (EPI)\n",
    "#             \"starting excess power analysis...generating summed spectrograms\"\n",
    "\n",
    "            if segPerTile>1:\n",
    "                tempS = 2\n",
    "            else:\n",
    "                tempS = 1           \n",
    "            \n",
    "            #Loop through the active stations\n",
    "            for i,station in enumerate(active):\n",
    "                #Calculate the normailized and unnormalized spectrograms for the different time tile sums.\n",
    "                #The frequency channels are summed with two combination, one starting at index 0 (\"Up\") and the other\n",
    "                # at index 1 (\"Down\") so that the gaps between frequency channels are covered.\n",
    "                # Mnu0 is the normalized \"up\" spectrogram, Mnd0 is the \"down\" spectrogram\n",
    "                # MnND is the unnormalized spectrogram with no frequency summing\n",
    "                # SxxN is the Normalized spectrogram with no frequency summing\n",
    "                \n",
    "                Mnu0[i], Mnd0[i], MnND[i], SxxN[i] = EPI(datalist[j][i],\n",
    "                                                          MnND[i],\n",
    "                                                          SxxN[i],\n",
    "                                                          segments_per_tile = tempS,\n",
    "                                                          channels_per_tile = chanPerTile,\n",
    "                                                          deltaTMinA = tTileWidthPrev,\n",
    "                                                          deltaFmin = 1./deltaTMin,\n",
    "                                                          ep_station = station,\n",
    "                                                          makeplot = False,\n",
    "                                                          show_intermediate = False\n",
    "                                                         )\n",
    "##################################################\n",
    "\n",
    "            #Pick out the threshold for the number of tiles summed\n",
    "            threshold0 = threshold0s[n]\n",
    "\n",
    "            shapeU = Mnu0[0].shape\n",
    "            shapeD = Mnd0[0].shape       \n",
    "           \n",
    "            #Initialize the time-freq arrays that record the number of stations above the threshold for \n",
    "            # both the \"up\" and \"down\" spectrograms\n",
    "            nStaAboveThreshU0 = np.zeros(shapeU)\n",
    "            nStaAboveThreshD0 = np.zeros(shapeD)\n",
    "            \n",
    "            #For each station, add 1 for every station with EP above threshold0.\n",
    "            #nStaAboveThreshU0 and nStaAboveThreshD0 are 2-D arrays with elements equal to the number of stations \n",
    "            # with EP above threshold0\n",
    "            for i in range(0,nStations):\n",
    "                nStaAboveThreshU0 += Mnu0[i] > threshold0           \n",
    "                nStaAboveThreshD0 += Mnd0[i] > threshold0\n",
    "                \n",
    "            #If a given tile is flagged in more than nCoin stations, mask that tile to recalculate the average PSD\n",
    "            # maskIndexU0 and maskIndexD0 are arrays of the indices of the flagged events for threshold0\n",
    "            maskIndexU0 = np.nonzero(nStaAboveThreshU0 > nCoin-0.5)\n",
    "            maskIndexD0 = np.nonzero(nStaAboveThreshD0 > nCoin-0.5)\n",
    "            \n",
    "            #Create a map of the time and frequency tiles that have more than nCoin stations above theshold0\n",
    "            eventSpec0 = np.zeros(MnND[0].shape)\n",
    "            eventSpec0 = np.copy(flagEvents(maskIndexU0, maskIndexD0, eventSpec0, chanPerTile))\n",
    "            \n",
    "            if PlotEventMaps:  \n",
    "                plotEventMap(eventSpec0, TLimit, tTileWidth, 'Threshold0')            \n",
    "                \n",
    "            #Initialize spectrograms for determining when new events are no longer being flagged\n",
    "            oldEventSpec = np.zeros(eventSpec0.shape)\n",
    "            newEventSpec = np.copy(eventSpec0)\n",
    "            loops = 0\n",
    "            \n",
    "###############################################################################################################\n",
    "            #Go through procedure with threshold0. Repeat until no more events are flagged or a max of 4 times\n",
    "            while np.any((oldEventSpec-newEventSpec)) and loops < 4:\n",
    "\n",
    "#             while loops < 1:\n",
    "\n",
    "                eventSpec0 = np.zeros(eventSpec0.shape)\n",
    "                for i,station in enumerate(active):\n",
    "                    #Calculate normalized spectrogram with the flagged events masked when calculating the average PSD\n",
    "                    # Mnu0 and Mnd0 are the \"up\" and \"down\" spectrograms\n",
    "                    Mnu0[i], Mnd0[i] = EPII(datalist[j][i],\n",
    "                                            Sxx0 = MnND[i],\n",
    "                                            deltaT = tTileWidth,\n",
    "                                            fx = fs,\n",
    "                                            Sxxmask = newEventSpec,\n",
    "                                            segments_per_tile = segPerTile,\n",
    "                                            channels_per_tile = chanPerTile,\n",
    "                                            ep_station = station,\n",
    "                                            show_intermediate = False,\n",
    "                                            makeplot = False\n",
    "                                           )\n",
    "\n",
    "                nStaAboveThreshU0 = np.zeros(shapeU)\n",
    "                nStaAboveThreshD0 = np.zeros(shapeD)\n",
    "\n",
    "                #Find the tiles that have an excess power above threshold0\n",
    "                for i in range(0,nStations):\n",
    "                    nStaAboveThreshU0 += Mnu0[i] > threshold0\n",
    "                    nStaAboveThreshD0 += Mnd0[i] > threshold0\n",
    "                \n",
    "                #If a given tile is flagged in more than nCoin stations, mask that tile to recalculate the average PSD.\n",
    "                maskIndexU0 = np.nonzero(nStaAboveThreshU0 > nCoin - 0.5)\n",
    "                maskIndexD0 = np.nonzero(nStaAboveThreshD0 > nCoin - 0.5)\n",
    "\n",
    "\n",
    "                eventSpec0 = np.copy(flagEvents(maskIndexU0, maskIndexD0, eventSpec0, chanPerTile))\n",
    "                oldEventSpec = np.copy(newEventSpec)\n",
    "                newEventSpec = np.copy(eventSpec0)\n",
    "\n",
    "                loops+=1\n",
    "                \n",
    "            if PlotEventMaps:  \n",
    "                    plotEventMap(newEventSpec, TLimit, tTileWidth, 'II Thresh 0')\n",
    "#############################################################################\n",
    "            #Go through procedure again, using the predetermined thresholds\n",
    "    \n",
    "            \n",
    "            #If a given tile is flagged in more than nCoin stations, mask that tile to recalculate the average PSD\n",
    "            # maskIndexU and maskIndexD are arrays of the indices of the flagged events for threshold1\n",
    "            \n",
    "            maskIndexU = np.copy(maskIndexU0)\n",
    "            maskIndexD = np.copy(maskIndexD0)\n",
    "            \n",
    "            for th, threshold1 in enumerate(thresholds[n]):\n",
    "                if threshold1 > threshold0:\n",
    "                    loopNum=10\n",
    "                else:\n",
    "                    loopNum=1\n",
    "            \n",
    "                \n",
    "                # start EP II upper\n",
    "                Mnu = np.copy(Mnu0)\n",
    "                Mnd = np.copy(Mnd0)\n",
    "                \n",
    "#                 print(\"EPII upper threshold\")        \n",
    "                loops = 0\n",
    "                eventSpec = np.zeros(eventSpec0.shape)\n",
    "                oldEventSpec = np.zeros(eventSpec0.shape)                \n",
    "                    \n",
    "                while np.any((oldEventSpec-newEventSpec)) and loops < loopNum:\n",
    "\n",
    "\n",
    "#                 newEventSpec = np.zeros(eventSpec0.shape)\n",
    "#                 while loops < 1:\n",
    "            \n",
    "                    eventSpec = np.zeros(eventSpec0.shape)\n",
    "                                    \n",
    "                    for i,station in enumerate(active):\n",
    "                        # Mnu and Mnd are the \"up\" and \"down\" spectrograms\n",
    "                        Mnu[i], Mnd[i] = EPII(datalist[j][i],\n",
    "                                              Sxx0 = MnND[i],\n",
    "                                              deltaT = tTileWidth,\n",
    "                                              fx = fs,\n",
    "                                              Sxxmask = newEventSpec,\n",
    "                                              segments_per_tile = segPerTile,\n",
    "                                              channels_per_tile = chanPerTile,\n",
    "                                              ep_station = station,\n",
    "                                              show_intermediate = False,\n",
    "                                              makeplot = True\n",
    "                                             )\n",
    "                        \n",
    "                    #Generate a 2-D array with elements equal to the number of stations \n",
    "                    nStaAboveThreshU = np.zeros(shapeU)\n",
    "                    nStaAboveThreshD = np.zeros(shapeD)\n",
    "\n",
    "                    #Find the tiles that have an excess power above threshold0\n",
    "                    for i in range(0,nStations):\n",
    "                        #Find the tiles that have an excess power above threshold1\n",
    "                        nStaAboveThreshU += Mnu[i] > threshold1\n",
    "                        nStaAboveThreshD += Mnd[i] > threshold1   \n",
    "\n",
    "                    #If a given tile is flagged in more than nCoin stations, mask that tile to recalculate the average PSD.\n",
    "                    \n",
    "                    maskIndexU = np.nonzero(nStaAboveThreshU > nCoin-0.5)\n",
    "                    maskIndexD = np.nonzero(nStaAboveThreshD > nCoin-0.5)\n",
    "                    \n",
    "                    #Find the indices for the mask based on whether or not there were >= nCoin stations with flagged events\n",
    "                    #The masking map is made using the minimum frequency channel \n",
    "                    \n",
    "                    eventSpec = np.copy(flagEvents(maskIndexU, maskIndexD, eventSpec, chanPerTile))\n",
    "                                        \n",
    "                    oldEventSpec = np.copy(newEventSpec)\n",
    "                    newEventSpec = np.copy(eventSpec)\n",
    "                    \n",
    "                    loops+=1\n",
    "\n",
    "                if PlotEventMaps:\n",
    "                    plotEventMap(newEventSpec, TLimit, tTileWidth, 'II Thresh 1')\n",
    "                \n",
    "                nEventsU = maskIndexU[0].size\n",
    "                nEventsD = maskIndexD[0].size\n",
    "                nEvents  = nEventsU + nEventsD\n",
    "                \n",
    "#               Assign the false positive probability for the given timesum, window, trial threshold and frequency \n",
    "\n",
    "#                  for up spectrogram\n",
    "                for f in maskIndexU[0]:\n",
    "                    fPosEP[2*f, n, th, j, z]   += float(1.0)/float(numberTtiles)\n",
    "#                  for down spectrogram\n",
    "                for f in maskIndexD[0]:\n",
    "                    fPosEP[2*f+1, n, th, j, z] += float(1.0)/float(numberTtiles)\n",
    "            \n",
    "            \n",
    "                #Initialize events arrays. \n",
    "                #eventsU is a 2-D array containing the EP values of the flagged tiles from the subtracted \"up\" spectrogram for each station\n",
    "                #eventsNSU is a 2-D array containing the EP values of the flagged tiles from the unsubtracted \"down\" spectrogram for each station\n",
    "                eventsU = np.zeros((nStations, nEventsU))\n",
    "                eventsD = np.zeros((nStations, nEventsD))\n",
    "                eventsNSU = np.zeros(eventsU.shape)\n",
    "                eventsNSD = np.zeros(eventsD.shape)\n",
    "                \n",
    "                specMask = np.zeros(eventSpec0.shape)\n",
    "                \n",
    "                if threshold1 < threshold0:\n",
    "                    specMask = np.copy(eventSpec0)\n",
    "                else:\n",
    "                    specMask = np.copy(eventSpec)\n",
    "                \n",
    "                for i,station in enumerate(active):\n",
    "                    #EPIII returns the unsubtracted and subtraced spectrograms.\n",
    "                    #MnSu,MnSd are arrays of the subtracted \"up\" and \"down\" spectrograms \n",
    "                    #MnNSu,MnNSd are arrays of not subtracted and not normalized \"up\" and \"down\"  spectrograms\n",
    "                    MnSU[i], MnSD[i], MnNSU[i], MnNSD[i]    =  EPIII(Sxx = MnND[i],\n",
    "                                                                     deltaT = tTileWidth,\n",
    "                                                                     fx = fs,\n",
    "                                                                     Sxxmask = specMask,\n",
    "                                                                     segments_per_tile = segPerTile,\n",
    "                                                                     channels_per_tile = chanPerTile,\n",
    "                                                                     ep_station = station,\n",
    "                                                                     show_intermediate = False,\n",
    "                                                                     makeplot = False,\n",
    "                                                                     subtract = False\n",
    "                                                                    )   \n",
    "                        \n",
    "#                     for k in range (MnSu[i][0].size):\n",
    "#                         MnSu[i][:,k] /= active_bwnorm[i][fxup.astype(int)-1]**2\n",
    "#                         MnSd[i][:,k] /= active_bwnorm[i][fxdn.astype(int)-1]**2\n",
    "                        \n",
    "#                     MnSu[i] /= active_unc_spin[i]\n",
    "#                     MnSd[i] /= active_unc_spin[i]\n",
    "                    \n",
    "                    #print(\"Mask Index U\", maskIndexU)\n",
    "                    print(\"Number of Active Stations\", nStations)\n",
    "                    eventsU[i]   = (MnSU[i])[maskIndexU]\n",
    "                    eventsD[i]   = (MnSD[i])[maskIndexD]\n",
    "                    eventsNSU[i] = (MnNSU[i])[maskIndexU]\n",
    "                    eventsNSD[i] = (MnNSD[i])[maskIndexD]\n",
    "                                                        \n",
    "\n",
    "                #Use the standard deviation of the unflagged events from threshold0 to calculate uncertainties if \n",
    "                #threshold1 < threshold0.\n",
    "                \n",
    "\n",
    "                    \n",
    "                if threshold1 < threshold0:\n",
    "                    stdDevEventsU = np.copy(calculateEventUnc(nStations, MnNSU, maskIndexU0, eventsNSU, nEventsU, maskIndexU))\n",
    "                    stdDevEventsD = np.copy(calculateEventUnc(nStations, MnNSD, maskIndexD0, eventsNSD, nEventsD, maskIndexD))\n",
    "                else:\n",
    "                    stdDevEventsU = np.copy(calculateEventUnc(nStations, MnNSU, maskIndexU, eventsNSU, nEventsU, maskIndexU))\n",
    "                    stdDevEventsD = np.copy(calculateEventUnc(nStations, MnNSD, maskIndexD, eventsNSD, nEventsD, maskIndexD))\n",
    "\n",
    "                consistency(active, stdDevEventsU, eventsU, maskIndexU, nEventsU, activeUnc, Mnu, threshold1,th)\n",
    "                consistency(active, stdDevEventsD, eventsD, maskIndexD, nEventsD, activeUnc, Mnd, threshold1,th)\n",
    "\n",
    "\n",
    "\n",
    "#                 for f in CoinSpectU[0]:\n",
    "#                     fPosCoin[2*f, n, th, j, z] += 1.0/float(numberTtiles)  \n",
    "#                 for f in CoinSpectD[0]:\n",
    "#                     fPosCoin[2*f+1, n, th, j, z] += 1.0/float(numberTtiles)  \n",
    "                \n",
    "                \n",
    "#                 for f in pFinalSpectU[0]:\n",
    "#                     fPosP[2*f, n, th, j, z] += 1.0/float(numberTtiles)  \n",
    "#                 for f in pFinalSpectD[0]:\n",
    "#                     fPosP[2*f+1, n, th, j, z] += 1.0/float(numberTtiles)  \n",
    "\n",
    "                    \n",
    "        stopStamp2 = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print (j,\" window,   time : \",(datetime.strptime(stopStamp2, \"%H:%M:%S\") - datetime.strptime(startStamp2, \"%H:%M:%S\")).seconds)\n",
    "                    \n",
    "    stopStamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print (\"\\n\\n\\n  trial time : \",(datetime.strptime(stopStamp, \"%H:%M:%S\") - datetime.strptime(startStamp, \"%H:%M:%S\")).seconds)\n",
    "\n",
    "                   \n",
    "                    \n",
    "fPosProbEP = np.mean(fPosEP,axis=(-1,-2))\n",
    "fPosProbCoin = np.mean(fPosCoin,axis=(-1,-2))\n",
    "fPosProbP = np.mean(fPosP,axis=(-1,-2))\n",
    "\n",
    "\n",
    "fPosAvgEP = np.mean(fPosProbEP,axis=0)\n",
    "fPosAvgCoin = np.mean(fPosProbCoin,axis=0)\n",
    "fPosAvgP = np.mean(fPosProbP,axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# False Positive Probability Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0vals = np.zeros((ntsums,nThreshs))\n",
    "threshold1s = np.copy(thresholds)\n",
    "\n",
    "cmap = plt.cm.tab20\n",
    "rcParams['axes.prop_cycle'] = cycler(color=cmap(np.linspace(0., 1., 20)))\n",
    "cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "colors1 = cycle[0::2]\n",
    "colors2 = cycle[1::2]\n",
    "\n",
    "print(\"average of {} {} second intervals\".format(ndates, TLimit))\n",
    "f2, ax = plt.subplots(1,figsize = (8,6))\n",
    "for i in range(0,ntsums):\n",
    "    ax.plot(thresholds[i],fPosAvgEP[i,:], 'o', color = colors1[i], label = '{}'.format(2*tsums[i])) \n",
    "    for j in range(nThreshs):\n",
    "        q0vals[i,j] = (Q0(threshold1s[i,j], 2.*tsums[i]*deltaTMin*fTileWidth, nStationsAvg, nCoin))\n",
    "\n",
    "for i in range(0,ntsums):\n",
    "    ax.plot(thresholds[i],fPosAvgCoin[i,:], 'o', color = colors2[i], label = '{}'.format(2*tsums[i]))\n",
    "            \n",
    "for i in range(0,ntsums):\n",
    "    ax.plot(thresholds[i],fPosAvgP[i,:], 'o', color = colors2[i], fillstyle = 'none', label = '{}'.format(2*tsums[i]))\n",
    "    \n",
    "# for i in range(0,ntsums):\n",
    "#     ax.plot(thresholds[i],q0vals[i], color = colors1[i], label = '{}'.format(2*tsums[i]))\n",
    "\n",
    "\n",
    "ax.set_title(\"False Positive Fraction (average {} {} s runs)\".format(ndates,TLimit))\n",
    "ax.legend(title = 'Time-Frequency volume \\n ($\\Delta T \\Delta F$, $\\Delta F = 2$ Hz):\\n $\\epsilon^*$:           $EventCoin$:             $p$: :', bbox_to_anchor=(1., 0.75, 1., .102), loc='upper left', ncol = 4)\n",
    "  \n",
    "ax.set_ylabel('$P_{N_{st},4}(\\epsilon > \\epsilon^*)$')\n",
    "ax.set_xlabel('$\\epsilon^*$')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f2, ax = plt.subplots(1,figsize = (8,6))\n",
    "for i in range(0,ntsums):\n",
    "    ax.plot(thresholds[i],fPosAvgEP[i,:], 'o', color = colors1[i], label = '{}'.format(2*tsums[i])) \n",
    "\n",
    "for i in range(0,ntsums):\n",
    "    ax.plot(thresholds[i],fPosAvgCoin[i,:], 'o', color = colors2[i], label = '{}'.format(2*tsums[i]))\n",
    "    \n",
    "for i in range(0,ntsums):\n",
    "    ax.plot(thresholds[i],fPosAvgP[i,:], 'o', color = colors2[i], fillstyle = 'none', label = '{}'.format(2*tsums[i]))\n",
    "   \n",
    "# for i in range(0,ntsums):\n",
    "#     ax.plot(thresholds[i],q0vals[i], color = colors1[i], label = '{}'.format(2*tsums[i]))\n",
    "\n",
    "\n",
    "ax.set_title(\"False Positive Fraction (average {} {} s runs)\".format(ndates,TLimit))\n",
    "ax.legend(title = 'Time-Frequency volume \\n ($\\Delta T \\Delta F$, $\\Delta F = 2$ Hz):\\n $\\epsilon^*$:           $EventCoin$:            $p$:', bbox_to_anchor=(1., 0.75, 1., .102), loc='upper left', ncol = 4)\n",
    "ax.set_yscale('log', nonpositive = 'clip')\n",
    "ax.set_ylim(10.**(-5),1.5)\n",
    "ax.set_ylabel('$P_{N_{st},4}(\\epsilon > \\epsilon^*)$')\n",
    "ax.set_xlabel('$\\epsilon^*$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fPosAvgEP[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fPosAvgCoin[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds[n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] =14\n",
    "EPbins=np.arange(0,1.1,0.1)\n",
    "for th, threshold1 in enumerate(thresholds[n]):\n",
    "    print(threshold1)\n",
    "\n",
    "    \n",
    "    f2, ax = plt.subplots(1,figsize = (8,6))\n",
    "    ax.hist(pValueDist[th][1:],label = \"$\\chi^2$ Value\")\n",
    "#     ax.hist(pZeroValueDist[th][1:], bins = EPbins,alpha=0.5,label = \"$p$ Value\")\n",
    "#     ax.set_title(\"$p$ and $p_0$ Value Distributions at $\\epsilon^* $ of {}  $pT^2$\".format(int(threshold1)) )\n",
    "    ax.legend(bbox_to_anchor=(1., 0.75, 1., .102), loc='upper left', ncol = 1)\n",
    " \n",
    "\n",
    "    ax.set_ylabel('Number of Events')\n",
    "    ax.set_xlabel('p Value')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] =14\n",
    "EPbins=np.arange(-4,4,0.05)\n",
    "for th, threshold1 in enumerate(thresholds[n]):\n",
    "    print(threshold1)\n",
    "\n",
    "    \n",
    "    f2, ax = plt.subplots(1,figsize = (8,6))\n",
    "#     ax.hist(pValueDist[th][1:], bins = EPbins,label = \"$\\chi^2$ Value\")\n",
    "    ax.hist(pZeroValueDist[th][1:],bins = EPbins,alpha=0.5,label = \"SpAvg/DelSp\")\n",
    "\n",
    "#     ax.set_title(\"$p$ and $p_0$ Value Distributions at $\\epsilon^* $ of {}  $pT^2$\".format(int(threshold1)) )\n",
    "    ax.legend(bbox_to_anchor=(1., 0.75, 1., .102), loc='upper left', ncol = 1)\n",
    " \n",
    "\n",
    "    ax.set_ylabel('Number of Events')\n",
    "    ax.set_xlabel('<sP>/delta<sP>')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pZeroValueDist[th][1:].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskIndexU[0].size+maskIndexD[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenum =\"600\"\n",
    "runType = 'Gaussian'\n",
    "folder = \"saved_files/\"+(datetime.now().strftime('%Y-%m-%d'))+\"/{}\".format(runType)\n",
    "directory = '{}'.format(folder)\n",
    "os.system('mkdir -p {}'.format(directory))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th, threshold1 in enumerate(thresholds[n]):\n",
    "\n",
    "    dfPvalue = pd.DataFrame(data=pValueDist[th][1:])\n",
    "    dfPvalue.to_csv(\"{}/{}FPosPvalue{}.csv\".format(folder,filenum,th)) \n",
    "\n",
    "    dfMvalue = pd.DataFrame(data=pZeroValueDist[th][1:])\n",
    "    dfMvalue.to_csv(\"{}/{}FPosMvalue{}.csv\".format(folder,filenum,th)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pZeroValueDist[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxlen =max([pZeroValueDist[th][1:].size for th, threshold1 in enumerate(thresholds[n]) ])\n",
    "\n",
    "# maxlen=10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
